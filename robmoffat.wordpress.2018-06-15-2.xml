<?xml version="1.0" encoding="UTF-8" ?>
<!-- This is a WordPress eXtended RSS file generated by WordPress as an export of your site. -->
<!-- It contains information about your site's posts, pages, comments, categories, and other content. -->
<!-- You may use this file to transfer that content from one site to another. -->
<!-- This file is not intended to serve as a complete backup of your site. -->

<!-- To import this information into a WordPress site follow these steps: -->
<!-- 1. Log in to that site as an administrator. -->
<!-- 2. Go to Tools: Import in the WordPress admin panel. -->
<!-- 3. Install the "WordPress" importer from the list. -->
<!-- 4. Activate & Run Importer. -->
<!-- 5. Upload this file using the form provided on that page. -->
<!-- 6. You will first be asked to map the authors in this export file to users -->
<!--    on the site. For each author, you may choose to map to an -->
<!--    existing user on the site or to create a new user. -->
<!-- 7. WordPress will then import each of the posts, pages, comments, categories, etc. -->
<!--    contained in this file into your site. -->

<!-- generator="WordPress/4.6.11" created="2018-06-15 15:38" -->
<rss version="2.0"
	xmlns:excerpt="http://wordpress.org/export/1.2/excerpt/"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:wp="http://wordpress.org/export/1.2/"
>

<channel>
	<title>robmoff.at</title>
	<link>http://robmoff.at</link>
	<description>Rob Moffat&#039;s Homepage</description>
	<pubDate>Fri, 15 Jun 2018 15:38:35 +0000</pubDate>
	<language>en-US</language>
	<wp:wxr_version>1.2</wp:wxr_version>
	<wp:base_site_url>http://robmoff.at</wp:base_site_url>
	<wp:base_blog_url>http://robmoff.at</wp:base_blog_url>

	<wp:author><wp:author_id>1</wp:author_id><wp:author_login><![CDATA[bobm]]></wp:author_login><wp:author_email><![CDATA[robmoffat@mac.com]]></wp:author_email><wp:author_display_name><![CDATA[bobm]]></wp:author_display_name><wp:author_first_name><![CDATA[rob]]></wp:author_first_name><wp:author_last_name><![CDATA[moffat]]></wp:author_last_name></wp:author>


	<generator>https://wordpress.org/?v=4.6.11</generator>

	<item>
		<title>What&#039;s It All About</title>
		<link>http://robmoff.at/2011/08/24/hello-world/</link>
		<pubDate>Wed, 24 Aug 2011 15:34:12 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://www.robmoffat.co.uk/?p=1</guid>
		<description></description>
		<content:encoded><![CDATA[Ok, time to resurrect the blog idea.

It's long been my intention to start a blog, populated with articles written in 20 minutes or less.  In fact, 20 minutes should easily cover it... people have short attention spans and the key to writing is to get as many ideas out in a short a space as possible.

So, what's this about?  Primarily, an exercise in writing, and seeing who reads it, but also about asking some questions which don't seem to get discussed on the internet, at least in the places I look.  Also, I'm going to try and make regular posts about what is happening with my software company, <a href="http://www.kite9.com">Kite9</a>.

Also, it's a place where I can try and get some ideas down about how the world is changing.  It seems to be changing too fast now for me to process it all as it happens, so here I am trying to make sense of it.

Well, here goes.  I expect you've arrived at this page sometime in 2012 and this is still the only blog entry on there.  Just like any great new year's resolution.  Made in September.

&nbsp;]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>1</wp:post_id>
		<wp:post_date><![CDATA[2011-08-24 15:34:12]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2011-08-24 15:34:12]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[hello-world]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="category" nicename="general"><![CDATA[general]]></category>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
			<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
	</item>
	<item>
		<title>Film Review - Superman 3</title>
		<link>http://robmoff.at/2011/09/07/film-review-superman-3/</link>
		<pubDate>Wed, 07 Sep 2011 13:12:08 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://www.robmoffat.co.uk/?p=10</guid>
		<description></description>
		<content:encoded><![CDATA[What this blog needs is more topical film reviews, and so here isn't one.  Superman 3 was released in 1983, so it's been around the block.  As a child I loved this film, and there was a disastrous afternoon at home once when the extremely-hard-to-operate prerecord facility on our VHS didn't work properly and we ended up with about half an hour of the film missing, necessitating a trip down to the video hire shop so we could watch the rest of it.

For kids, there are great bits like when Superman goes bad and moves the Leaning Tower Of Pisa.  And when he loses his powers and has a fight in a bar.  Also, luckily, he doesn't resort to time-travelling shenanigans (like in the first one) to get him out of a plot hole.  Even at age 10 that seemed really suspect.
<h2>Two Keys?</h2>
<a href="http://robmoff.at/wp-content/uploads/2011/09/richard-pryor-superman3-10.jpg"><img class="alignright size-medium wp-image-35" title="richard-pryor-superman3-10" src="http://robmoff.at/wp-content/uploads/2011/09/richard-pryor-superman3-10-300x199.jpg" alt="" width="300" height="199" /></a>Watching it again through adult eyes, Richard Pryor clearly stands out.  "Two keys?  At the same time?".  Genius.  On the downside, the plot hasn't aged well.  It's typical 80's fare, wherein a gifted computer hacker with a computer can really achieve anything at all.   Weird Science and Tron both followed the same trope.  I don't think you'd get a plot like that nowadays.  The problem is that people are just too used to computers already, and know their limitations.

Back in 1983, Richard Pryor could easily create a computer that would become sentient, turn people into killer robots, hijack the electric grid and fire missiles at Superman.  People just wouldn't buy that anymore.    Time and again, people have been let down by AI research, so that the malevolence we come to expect from the computer is the kind of annoyance that you find on an automated call answering system, or the amount of junk mail we get.
<h2>Creating Robots</h2>
<a href="http://robmoff.at/wp-content/uploads/2011/09/s3robot.jpg"><img class="size-medium wp-image-34 alignright" title="s3robot" src="http://robmoff.at/wp-content/uploads/2011/09/s3robot-300x127.jpg" alt="" width="300" height="127" /></a>In many ways though, the modern computer could be so much more malevolent:  we've got the internet now, and records about every aspect of our lives have been computerised.  The Superman 3 computer wouldn't bother creating robots: it would steal all our credit card details and run up bills, hack our mobile phones, steal our social security information, hack into the Pentagon files and publish them on the internet and give us all the wrong doses of radiation on the hospital scanner.

Except that we don't need an evil computer to do those things, they've all already happened.  As well as being a massively connected computer network, the internet connects together such a vast network of miscreants and halfwits that we don't actually need an evil AI at all.

When one finally comes along, it can just join the back of the queue.

&nbsp;

&nbsp;

&nbsp;

&nbsp;]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>10</wp:post_id>
		<wp:post_date><![CDATA[2011-09-07 13:12:08]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2011-09-07 13:12:08]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[film-review-superman-3]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="category" nicename="film"><![CDATA[film]]></category>
		<category domain="category" nicename="internet"><![CDATA[internet]]></category>
		<category domain="category" nicename="singularity"><![CDATA[singularity]]></category>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
			<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_thumbnail_id]]></wp:meta_key>
			<wp:meta_value><![CDATA[33]]></wp:meta_value>
		</wp:postmeta>
	</item>
	<item>
		<title>Facebook and the Monopoly</title>
		<link>http://robmoff.at/2011/09/07/facebook-and-the-monopoly/</link>
		<pubDate>Wed, 07 Sep 2011 20:35:13 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://www.robmoffat.co.uk/?p=16</guid>
		<description></description>
		<content:encoded><![CDATA[<a href="http://en.wikipedia.org/wiki/Metcalfe's_law">Metcalfe's law</a> (due to Bob Metcalfe, who came up with ethernet, the network your office is probably using) said that any network's value is based on the number of users in it.

It's a rule that Facebook, Google+, MySpace, LinkedIn and all the others have taken to heart - the value of their social networks is all about the number of users.

However, it's about something else too - their ability to form a monopoly, wherein they are able to lock in users by providing unique features or making it hard to move to a new network.

Theoretically, Facebook could allow you to be Facebook friends with people on the LinkedIn network.  Or vice versa.  But they don't.

If they did, it would create an interesting dynamic:  they would reduce their monopoly power, but increase the size of their network.  It's swings and roundabouts.  What you would gain through Metcalfe's Law, you would lose from your monopoly.
<h2>Monopoly Profits</h2>
That's all fine, except that obviously <a href="http://en.wikipedia.org/wiki/Monopoly">monopolies</a> are bad for consumers, which is why governments usually do their best to limit their powers.  For example, Facebook seems ok to me, but maybe Google+ is better?  I have no idea, since I have little interest in trying to rebuild my social network in a different system.  Facebook keeps my business because that's where everyone else is.

I'm not that bothered, but I can't help but feel that its slightly bizarre that a glorified address book has come to dominate a large part of what should be a utility function of the internet.

So how could these monopolies be curtailed on the social network sites?

Long ago, Google tried to build <a href="http://techcrunch.com/2011/07/22/google-plus-opensocial-facebook/">Open Social.</a>  It was a kind of common language that could work with any social network, and do exactly the kind of other-network friend thing I'm talking about. Obviously, all of the smaller/dying networks wanted to get involved, as it would increase the value of their networks.  Also obviously, Facebook wasn't interested, as it would reduce their monopoly position.

If this had taken off, I guess it wouldn't matter if you were on Facebook, LinkedIn, Google+ or ran your own social network on a server somewhere. And you'd be able to move from one provider to another really easily.

But it didn't take off, and it's kind of obvious that it wouldn't.
<h2>Catch</h2>
There's a Catch 22 situation here:  building a social network is no easy task - it's going to be expensive.  So you need the promise of the monopoly profits in order to make it worthwhile.  So sadly, for the forseeable future, every social network is also going to try and be a social monopoly.

Google+, the newest entrant to the market has turned its back on Open Social, and is basically trying to "do a Facebook" over again but with a different name.  That's all about maintaining their monopoly on advertising.

Shame on you, Google - you were right the first time.  If anyone had the resources to break the monopoly and open this thing up, it's them.

---

P.S. In a later article, I will argue that in actual fact this monopoly is unsustainable in anything but the short term.  One day, our address books will be our own again.

&nbsp;

&nbsp;

&nbsp;

&nbsp;]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>16</wp:post_id>
		<wp:post_date><![CDATA[2011-09-07 20:35:13]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2011-09-07 20:35:13]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[facebook-and-the-monopoly]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="category" nicename="internet"><![CDATA[internet]]></category>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
			<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_thumbnail_id]]></wp:meta_key>
			<wp:meta_value><![CDATA[31]]></wp:meta_value>
		</wp:postmeta>
	</item>
	<item>
		<title>Now It&#039;s Books</title>
		<link>http://robmoff.at/2011/09/13/now-its-books/</link>
		<pubDate>Tue, 13 Sep 2011 12:44:37 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://www.robmoffat.co.uk/?p=28</guid>
		<description></description>
		<content:encoded><![CDATA[The Internet Disruption Engine <a href="http://techcrunch.com/2011/09/09/death-of-books/">moves onto books</a>.  Amazon sells more <a href="http://www.fastcompany.com/1754259/amazon-declares-the-e-book-era-has-arrived">e-books</a> than real books.  So what has already occurred in the music industry and the newspaper business is happening in the film industry, happened to the games industry and the rest of the bought software industry now comes to book publishing.

The dynamics of each are different, but the underlying cause is all the same:  IT is revolutionising the media industry big style.
<h2>Music</h2>
Music has been changed in two key ways.  Firstly, creating music is no longer expensive.   A bog standard laptop can do today what room full of high tech gear could do ten years ago.   Now you can compose the next number one on the 'plane, rather than in <a href="http://en.wikipedia.org/wiki/The_Manor_Studio">Richard Branson's studio</a>.

The second key change has obviously been around publication.   Up until CDs, technology served to drive up audio quality.  With CDs, and then with all subsequent changes, it has been about reducing cost and improving convenience.  Now, the marginal cost (i.e. cost to sell a single extra unit) of an online single is practically zero.
<h2>Television</h2>
Unlike music, producing television is still very expensive.  We are along way from being able to produce TV shows of discernable quality using a laptop, though advances in technology have reduced the costs at the lower end massively.  If I wanted to publish a podcast of myself talking about fish, that would have little overhead. Making a series of Doctor Who myself will require a budget.

Television publishing is in many ways ahead of the curve.  Most TV is free at the point of consumption, and paid for by advertising.  Much like a google search is.  TV is also evolving from being a temporally fixed broadcast to consume-when-you-want, whether this is via TiVo/Sky+ style recording or downloadable content.    The marginal cost of an extra consumer of television is zero.   The problem that TV is facing is that online advertising is much better targeted than TV advertising.  In order to keep it's share of advertising, TV is going to need to know who is watching it, and target adverts to the individual viewer.  Also, you're going to need some way of making sure that viewer doesn't skip over it.
<h2>What Happens When Marginal Cost is Zero?</h2>
Authoring books is as cheap and easy as authoring music (i.e. time and a laptop).  Publishing books is also now as cheap and easy as music (i.e. zero).

But what is the result of this?  Firstly, when you have a product who's marginal cost is low, you open yourself up to the possibility of piracy.   The producer takes the risk of the up-front costs of production, but after that pirates could step in and undercut you on any cost you charge to recoup this.

Also, in any of these media, where the cost of production could be zero, you will need to compete with budget offerings produced which have very low production costs, and a glut of low-to-no cost competitors.

This means that in any media business, competing with 'free' is going to be a real issue, whether the item is free because it was produced by amateurs, or because it's free because it's been pirated.
<h2>What Will Happen To eBooks?</h2>
Clearly, Amazon and Apple are having a field day selling music, ebooks and apps for anything like as much as their physical world equivalents.  It's pure profit and this will be eroded away by two forces:  businesses coming into the market to sell the same products as Amazon but for less, and authors/musicians etc. discounting their wares to gain market share over their competitors.

Arguably, this is <a href="http://techcrunch.com/2009/05/20/report-iphone-applications-are-getting-cheaper/">already happening with the AppStore</a>.

[caption id="" align="aligncenter" width="607" caption="AppStore Prices"]<img title="AppStore Prices" src="http://tctechcrunch.files.wordpress.com/2009/05/price_distribution.png?w=640" alt="" width="607" height="517" />[/caption]

That took a while to happen in the world of apps, <a href="http://www.teleread.com/publishing/despite-agency-model-indications-are-that-average-ebook-price-going-down/">but this may be happening to eBooks already</a>.
<h2>A Counter Example</h2>
Scientific journals seem to exist in a world of their own however.   Scientific papers are published in a journal to gain the attention of the audience of other scientists working within the field.  As<a href="http://www.monbiot.com/2011/08/29/the-lairds-of-learning/"> George Monbiot </a>points out, despite the fact that the internet was invented for the purpose of sharing scientific information, journal publisher monopoly power has actually increased over the years.

There are two differences that allow them to maintain their monopoly while others are losing theirs.  Firstly, appearance in a journal is a mark of achievement.  A lot of the value of a scientist's work is in the journals he or she has been published in.  A piece of research posted on the internet by a scientist will attract little attention on its own.    So value is created by the quality control gating of the journal itself.

Secondly, while journals sell to individuals on subscription, a lot of their business is to universities, which are charged extortionate fees.  Because universities are sufficiently few in number, and their libraries are easily accessible, it is easy to see which universities have paid their subscriptions and which haven't.  This means that the copyrights on journal articles actually mean much more than they do for other forms of media where policing copyright is nigh on impossible.

Note that journals are available online, if you have paid for the subscription.  Their marginal cost for readers of articles is also zero.  What the universities are paying for is a content filtering process which is recognised in its quality by scientists who wish to appear in it.  Scientists who have their work published in a journal gain credibility through being attached to a brand.
<h2>Money In Publishing</h2>
How can it be that a content aggregation service is worth more than the content itself?   It's all about branding.  In a world where a lot of content is free (legally or otherwise), and we are literally swimming in choice, good brands stand out like a beacon above everything else.    While we are less willing to pay for data, we are (as usual) happy to pay for time saved.   Recognised brands allow us to save time searching and filtering ourselves.

The Journal Publisher model is one which the Times / Economist and other paywall-publications are now following:  proprietary, edited content supporting a brand which must be subscribed to.  However, because they are generalist publications, they are unable to dominate their markets in the same way as the journal publishers (which make massive monopoly profits).

More to come

&nbsp;

&nbsp;

&nbsp;]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>28</wp:post_id>
		<wp:post_date><![CDATA[2011-09-13 12:44:37]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2011-09-13 12:44:37]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[now-its-books]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="category" nicename="information-theory"><![CDATA[information theory]]></category>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
			<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_thumbnail_id]]></wp:meta_key>
			<wp:meta_value><![CDATA[47]]></wp:meta_value>
		</wp:postmeta>
	</item>
	<item>
		<title>Getting Cheaper</title>
		<link>http://robmoff.at/2011/09/27/getting-cheaper/</link>
		<pubDate>Tue, 27 Sep 2011 11:07:30 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://www.robmoffat.co.uk/?p=59</guid>
		<description></description>
		<content:encoded><![CDATA[Here are three trends:
<h2>1) Automation is becoming smarter.</h2>
In the beginning, the industrial revolution came for all the farming jobs, and now less than 2% of people in the UK work in farming.  Down from nearly everyone in the feudal ages.  It's still reducing, as the chart below shows.  And usually, jobs removed in one sector get replaced by jobs in another sector.

[caption id="attachment_60" align="aligncenter" width="556" caption="Agricultural Employment over Time"]<a href="http://robmoff.at/wp-content/uploads/2011/09/Screen-shot-2011-09-21-at-23.27.09.png"><img class="size-full wp-image-60" title="Screen shot 2011-09-21 at 23.27.09" src="http://robmoff.at/wp-content/uploads/2011/09/Screen-shot-2011-09-21-at-23.27.09.png" alt="" width="556" height="254" /></a>[/caption]
<p style="text-align: left;">A Google search does in seconds what a librarian or researcher would have taken months to do.  A "Computer" used to be a job title, not the name of a machine.</p>
<a href="http://www.bbc.co.uk/news/technology-11508351">They have now built cars which drive themselves</a>.  <a href="http://blogs.cars.com/kickingtires/2006/09/ls_460_parking.html">Cars can already park themselves</a>.  This implies that soon delivery drivers, cab drivers, haulage drivers will soon have to go and find something else to do.
<h2>2) So, labour is becoming smarter.</h2>
People spend longer in education now than they ever have.

[caption id="attachment_61" align="aligncenter" width="597" caption="Students vs Population in the UK"]<a href="http://robmoff.at/wp-content/uploads/2011/09/Screen-shot-2011-09-21-at-23.34.25.png"><img class="size-full wp-image-61" title="Screen shot 2011-09-21 at 23.34.25" src="http://robmoff.at/wp-content/uploads/2011/09/Screen-shot-2011-09-21-at-23.34.25.png" alt="" width="597" height="591" /></a>[/caption]
<p style="text-align: left;">This implies that low skilled jobs either aren't there anymore, or they're being offshored to BRICs, or immigration, or fewer permanent jobs.  Unemployment getting higher in Britain.</p>

<h2>3) CEOs are Being Paid More, Relatively</h2>
There are websites investigating this...

<a href="http://www.aflcio.org/corporatewatch/paywatch/ceopay.cfm"><img class="aligncenter" title="CEO Pay, from alfcio.org" src="http://www.aflcio.org/issues/jobseconomy/jobs/images/ceopay_2011.jpg" alt="" width="450" height="450" /></a>
<h2>Conclusion: A Shift In Fortunes</h2>
In feudal Britain, land was the most important resource, and people who owned land were rich.  With the industrial revolution, the balance changed, and capital and the workforce were empowered:  you could make lots of things with machinery instead of land.

The balance of power is shifting away from the workers again, to such an extent that a lot of people aren't workers anymore.  The scope of what can be automated is expanding all the time.  This means that fewer and fewer traditional jobs will remain, and capital can replace labour to do these jobs.

Traditionally, whenever technology has displaced labour from one industry, others have appeared to take their place.   For example, call centres were an unthinkable proposition to agrarian society.

Technology increasingly replaces labour wherever there is a process that can be automated: bureacracy or monitoring are good examples.   However it is now moving into areas of where skills were commoditised, and actual presence is not required:  translation, driving, research.

In order to avoid your job being replaced by technology, you need to have a job where:
<ol>
	<li>Presence adds significant value (i.e. you are not just interacting with a machine), or enables the job to be done</li>
	<li>You are demonstrating significant variability, flexibility, creativity and autonomy such that the job either can't be automated, or the effort of doing so exceeds the reward.</li>
</ol>
<h2>Underemployment</h2>
Here are the big questions:
<ol>
	<li>Are there people now in society who have no skills over and above what can be provided by technology?  At least, skills not valued enough by the economy to make them worth paying for?  What will become of all the taxi drivers and lorry drivers?</li>
	<li>How long will it take for technology to catch up with all the people in jobs?  All skills will be automatable eventually.</li>
	<li>What happens to the concept of the economy, if the workforce aren't working?</li>
	<li>What happens to social security?  Will we all be paid to not work?</li>
</ol>
&nbsp;]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>59</wp:post_id>
		<wp:post_date><![CDATA[2011-09-27 11:07:30]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2011-09-27 11:07:30]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[getting-cheaper]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="category" nicename="singularity"><![CDATA[singularity]]></category>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
			<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_thumbnail_id]]></wp:meta_key>
			<wp:meta_value><![CDATA[70]]></wp:meta_value>
		</wp:postmeta>
		<wp:comment>
			<wp:comment_id>27</wp:comment_id>
			<wp:comment_author><![CDATA[The Human Change Agent : illogicalconclusion]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.robmoffat.co.uk/2012/05/04/the-human-change-agent/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[178.79.152.8]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-05-05 13:48:01]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-05-05 13:48:01]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] What this blog needs is more topical film reviews, and ...       [...]]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
				<wp:meta_value><![CDATA[a:4:{s:4:"time";s:15:"1372615778.8207";s:7:"message";s:43:"bobm changed the comment status to approved";s:5:"event";s:15:"status-approved";s:4:"user";s:4:"bobm";}]]></wp:meta_value>
			</wp:commentmeta>
		</wp:comment>
		<wp:comment>
			<wp:comment_id>30</wp:comment_id>
			<wp:comment_author><![CDATA[Profit, Efficiency and Time : illogicalconclusion]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.robmoffat.co.uk/2012/05/11/profit-efficiency-and-time/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[178.79.152.8]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-05-11 08:37:59]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-05-11 08:37:59]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] What this blog needs is more topical film reviews, and ...       [...]]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
				<wp:meta_value><![CDATA[a:4:{s:4:"time";s:15:"1372615778.7992";s:7:"message";s:43:"bobm changed the comment status to approved";s:5:"event";s:15:"status-approved";s:4:"user";s:4:"bobm";}]]></wp:meta_value>
			</wp:commentmeta>
		</wp:comment>
	</item>
	<item>
		<title>Faster Star Wars</title>
		<link>http://robmoff.at/2011/10/10/faster-star-wars/</link>
		<pubDate>Mon, 10 Oct 2011 11:47:31 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://www.robmoffat.co.uk/?p=74</guid>
		<description></description>
		<content:encoded><![CDATA[When I was a young lad in Felixstowe, the release of Return of the Jedi was a massive event.  We all patiently queued up at the single cinema, paid our money and were duly blown away by Lucas' amazing space opera.  We then went about collecting figures, and stickers, and lunchboxes and so forth, pouring money into Skywalker ranch.   And we were happy.  Apparently, this happened in May 1983, although I expect by the time Felixstowe got the film, it was more like June or July.

We didn't have a VHS player at the time, but apparently in 1986, it was released there - 3 years later.

I had to wait fully until 1989 to see it again on television.  That's six years later.  Six years!

Nowadays, you'd be unlikely to have to wait more than a few months for a DVD, and maybe a couple of years before it's shown on TV.

So what's happening there then?
<h2>Erosion of the Paywall</h2>
The reason that Star Wars appears on TV sooner now, is that there is no effective way to put a paywall around the film for a long period of time.   Consider how the technology for recording a film has changed:
<ol>
	<li>First, there was human memory.  This is a poor recording medium, but generally means that people don't usually go and see a film many times.  Because you have the memory of the film, you don't enjoy it as much on subsequent views.</li>
	<li>Then, there was the VHS recorder:  if it was on TV, you could record it and keep it.</li>
	<li>Then, there was the VHS-to-VHS copier, or you could string together a couple of VHS machines.   This was better still, but quality suffered for each recording.</li>
	<li>Then, we had DVD copiers.  Each DVD was just as good as the last one, making it easy to knock off perfect versions of the original film</li>
	<li>Then, we had the internet, which meant that there was no need for physical proximity in order to make the copy of the original film.  Distributors have to rush the disc release out before everyone pirates it on the internet.  A single copy leaked (by someone pirating a film reel, or an in-house copy, or simply sitting in the theater with a video camera) to the internet can then be watched by anyone.</li>
</ol>
So the paywall back in 1983 was constructed of an immense technical barrier (no means to record the film) and a temporal barrier (we'll show you the film on TV when we've completely milked the cinema outing).

Nowadays, there is no technical barrier, and the temporal barrier only exists until a bad penny in the corporation puts the master on the internet.
<div><span class="Apple-style-span" style="font-size: 20px; font-weight: bold;">Price vs Value of Information</span></div>
In any media industry, the same problem applies.  For undifferentiated information which has value to a large audience, the price will tend to zero.  The larger the audience having value from the information, and the better they are equipped technologically, the faster the price will tend to zero.

I can think of only two solutions to the problem:
<h3>1.  Differentiate your information to the level of individual customers</h3>
If you can find a way to provide higher information value to a customer by differentiating the information, go for it.   For example, stock information is free on the internet.  However, information specific to my portfolio of stocks is not available on the internet - no one else would get any value from it (unless they were up to something underhand).

This is a real problem for mass media - their model is going to become more and more broken.  However, it might mean that we need to fall back on differentiated media - for example, going to gigs, the theatre, playing games or interactive internet entertainment.
<h3>2.  Provide non-information value add.</h3>
This might be, for example, access to events, better packaging etc, as this can't be reproduced by others.

iTunes provides this through its library interface, and convenience of buying songs.  The value is not in the songs themselves (cos hey, you could easily steal those), but in the convenient way of accessing them.
<h2>Where to Go?</h2>
It's an interesting thought that George Lucas made more money on selling those figures, lunchboxes (and subsequently DVDs and the new Blu-Ray) than he did the actual cinema releases.

There's a strong argument that at some point in the future, it might be that the films are given away, and the latter day Lucas will make all his money from selling the sticker albums.

&nbsp;

&nbsp;

&nbsp;

&nbsp;

&nbsp;

&nbsp;

&nbsp;

&nbsp;]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>74</wp:post_id>
		<wp:post_date><![CDATA[2011-10-10 11:47:31]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2011-10-10 11:47:31]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[faster-star-wars]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="category" nicename="information-theory"><![CDATA[information theory]]></category>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
			<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_thumbnail_id]]></wp:meta_key>
			<wp:meta_value><![CDATA[75]]></wp:meta_value>
		</wp:postmeta>
	</item>
	<item>
		<title>Starbucksing the Library</title>
		<link>http://robmoff.at/2011/10/18/starbucksing-the-library/</link>
		<pubDate>Tue, 18 Oct 2011 13:45:03 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://www.robmoffat.co.uk/?p=91</guid>
		<description></description>
		<content:encoded><![CDATA[<img class="alignright" title="Zombie Librarians" src="http://blogs.rsc-wales.ac.uk/lr/files/2009/01/zombielibrarians.jpg" alt="" width="297" height="338" />The other week I was talking to a guy at <a href="http://www.15queenstreet.org/">15 Queen Street </a>who was building a website to allow planners to figure out how much it would cost to run a building.  Who would use this?  Apparently, companies thinking about buying Libraries from councils in the UK.  You enter details of the size of the library, and out pops a number of how much it would cost to run.   It's like a ready reckoner before you call in the surveyors.  Once you have bought the library, you are obliged to use it as some kind of "public space", which I expect will mean opening a branch of Starbucks in there.

So, it turns out that there are enough libraries in the UK being sold to make this worth building a website for.  I was slightly shocked and dismayed that our libraries are being jilted by local government.

But then I actually went to the library.

The computers in there were getting lots of use.  No one was reading the books.  A lady came in to look at the copy of "Good Housekeeping" and then left again.  The cafe was a disaster.   Only the children's area seemed really happening.
<h2>The Squeeze</h2>
So is the writing on the wall for the library?  Here are two issues:

<span class="Apple-style-span" style="font-size: 15px; font-weight: bold;">1.  Everything's on the internet</span>

The idea of going to your library to <em>look something up</em> or <em>check out the reference section</em> seems incredibly dated.  For general knowledge, you're far better off googling it.   However, as discussed in <a href="k/2011/09/13/now-its-books">Now It's Books</a>, if you want high quality scientific research, you (or your library) needs to pay a fortune.  This leaves libraries stuck in the middle - they clearly can't compete with either of these two extremes, and also there's a walk involved in getting there.
<h3>2.  eBooks</h3>
The second problem is eBooks.  Or, eEverything if you like.  Libraries are a collection of physical media, and their utility is limited because only one person can read any given book at a time.  The library would have to buy multiple copies in order for lots of people to read the same book at the same time.  This problem doesn't exist with digital information: the cost of reproduction is close to nil.

In <a href="/2011/10/10/faster-star-wars/">Faster Star Wars</a> I argued that the more value generated by a piece of mass media, the faster it's price would approach zero.  This is going to be  a real problem for eBooks, and before it's a problem for them, it will make libraries redundant.  If you can get a (digital) copy of your own of any given book for a very low sum (approaching zero over time) then the benefits of borrowing from a library diminish.
<h2>The eLibrary</h2>
Will we get eLibraries?  Well, it depends what one is.  The 'lending' part of the library will have to go:  you can't lend an ebook effectively, as people can just copy it and then give it back, so any library would have to work on the basis of being a "giving" library instead:  you join and get books for free.

Will this happen?  Perhaps.  Just as in the way we have lots of free, open source software available, it's likely that one day, rather than publishing a book, you'll just put it on the internet for free.   I doubt we would call it a library any more though, it would just be part of the internet.
<h2>What Could Governments Do?</h2>
With the money saved from not running libraries, the government should do two things:

1.  eBook Tokens

Simply give people money to spend on eBooks of their choice, at Amazon or wherever.  These would have a face value, allowing people to buy a certain quantity of books each year.   Amazon would be able to claim a fraction of this face value back from the government as profit.  Net result:  hopefully, more people in the UK reading books.

2.  Start Digitising

If you're running a library and you have a large collection of local information, then the government should pay some more of it's money saved on helping to get that digitised and up on the internet.   Once this is done, you can happily sell the collection knowing that the information within it is preserved for perpetuity.  With any luck, opening up a collection like this will get much more value out of it.
<h2>Upshot</h2>
I have fond memories of the library.  Much of my youth was spent traipsing to and from it in order to stay in books, but what I saw in Colchester Library was... different.   If it had been like the library of my youth, I would be up in arms about saving it.  But the fact that it was so empty, so unloved... maybe times are just changing.  And libraries are going to need to change with them.  I accept that my views are based on a sample of one library, and it was in Essex.  But hey, there's at least one less library we need right there.

&nbsp;]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>91</wp:post_id>
		<wp:post_date><![CDATA[2011-10-18 13:45:03]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2011-10-18 13:45:03]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[starbucksing-the-library]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="category" nicename="information-theory"><![CDATA[information theory]]></category>
		<category domain="category" nicename="internet"><![CDATA[internet]]></category>
		<category domain="category" nicename="singularity"><![CDATA[singularity]]></category>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
			<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_thumbnail_id]]></wp:meta_key>
			<wp:meta_value><![CDATA[93]]></wp:meta_value>
		</wp:postmeta>
	</item>
	<item>
		<title>Myers-Briggs</title>
		<link>http://robmoff.at/2011/11/02/myers-briggs-racism/</link>
		<pubDate>Wed, 02 Nov 2011 16:49:44 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://www.robmoffat.co.uk/?p=103</guid>
		<description></description>
		<content:encoded><![CDATA["Well, the Nazi's were obviously racists," explained Oberfeldwebel Jones.  "I mean, they simply said that everyone who is Jewish was bad.  There's no comparison.  What we're doing is a rigorous, scientific examination of different types of personality, and then removing the ones that are not productive in the modern world.  You could call it evolution."

After this years purges, estimates currently put the number of ISTP personalities down at 1%.  Most of those remaining had left or gone into hiding: locked in cellars until the purge was over.  Was this really progress?

If you looked back, it all seemed quite simple: initially, Myers-Briggs came up with a personality type system.  It caught on in the offices up and down the land, and people used it to examine why it was that they had disagreements with their colleagues.

"Oh, it's because we're different personality types!"  the answer was so helpful.  It explained why people couldn't agree, couldn't listen, couldn't work together.  Then it went further.

Reports came in of companies that deliberately hired certain types of people to get along with the ones they already had, and they used MBTI to do it.  Before long, you had to put your MBTI on your CV.  A bit further down the track and it appeared on the list of recruiter's requirements. And there were definitely types that were more in demand than others.

Eventually, some companies realised that they could hire the ISTPs that no-one else wanted, and run a business.  But they started getting a bad reputation, and looking "unclean".

It wasn't long before the government stepped in and started setting up camps for unemployed/unemployable ISTPs.  It was mostly the EIFJs that came up with the idea, they were the top dogs now.  But over the last 6 months, with camps full to bursting point, the government had started enacting "population reduction" strategies: the final solution.
<h2>Tigers</h2>
"Listen," said Jones, with his finger pointed at me.  "If you saw a huge, orange and black striped cat, you might be inclined to stereotype it as a tiger.  Additionally, you might also stereotype all tigers as being likely to kill people if left to their own devices.  Why would you do this?  Self defence.  And you'd be right to do so."

"The problem in this country is all the ISFP's - the liberals.  They say, just because something is a tiger, doesn't mean it wants to eat you.  I say, nonsense."

I was having trouble relating this argument.  "So are you saying stereotypes are good, or bad?" I asked him.

"They're good, " was Jones unequivocal reply.  "They save you from tigers.  They save you from ISTPs.  Where's the problem?"

"What about Blacks, or Jews, or the French?" I ask, trying to inject an extra, non-feline dimension into it.  "People often don't like those labels, do they?  I mean, isn't it wrong to label someone just so you can attach some stereotypical notions to it?  Aren't people a whole lot more complicated than that? "

"Well look, " said Jones.  "The great thing about MBTI is that we're not just basing these classifications on external characteristics like those.  We're actually delving into personality here.  That's why we have the personality testing.  Really, MBTI is just reflecting back on a person, and showing everyone exactly who they are."

"But what if it's wrong? " I blurted out.  "There's no way to check any of this stuff.  What if these classifications are arbitrary, and maybe don't really have that much impact on decision making?  They surely can't be telling the whole story.  The brain is massively more complex than a four-dimensional grid.  And what if actually people are meant to be a bit more of a closed book?  Surely making prejudgements of people is wrong, regardless of what they are based on... I mean, I know everyone does it anyway, it's human, but is there any reason to get people doing it more often than they already are?"

But it was too late.  Jones reached down and opened the drawer in his desk.  He pulled out a folder and handed me a fresh MBTI questionnaire to fill in.

"I think, " said Jones.  "That somehow we had you wrong before.  Lets do another one of these, eh?"

&nbsp;

&nbsp;]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>103</wp:post_id>
		<wp:post_date><![CDATA[2011-11-02 16:49:44]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2011-11-02 16:49:44]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[myers-briggs-racism]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="category" nicename="management"><![CDATA[management]]></category>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
			<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_thumbnail_id]]></wp:meta_key>
			<wp:meta_value><![CDATA[107]]></wp:meta_value>
		</wp:postmeta>
	</item>
	<item>
		<title>The Human Change Agent</title>
		<link>http://robmoff.at/2012/05/04/the-human-change-agent/</link>
		<pubDate>Fri, 04 May 2012 14:41:48 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://www.robmoffat.co.uk/?p=116</guid>
		<description></description>
		<content:encoded><![CDATA[Evolution has come a long way.  In the olden days, it was just really, really painful to watch.  All those enzymes and amino acids mucking about in the primordial soup.   It's a wonder we ever got anywhere.

Once DNA came along, things started looking up - it was the first successful standardization effort that we've seen on Earth.  Suddenly, (by this I mean over millions of years) the genetic code was reduced to a simple alphabet of G, T, A &amp; C - adenine, guanine, cytosine and thymine).   This was like lego for evolution, and meant that bits of genetic codes could cross from one organism to another and move around.   It really sped the whole process up.

This is <strong>meta-evolution:  </strong>the process of evolving itself had changed, and gotten faster.  (the meta-prefix means that this is the evolution of evolution).<!--more-->

Over the millions of years following, evolution carried on getting better: cells and cellular life-forms, multi-cellular  life forms (same cells in different orders makes different organisms), sex as a means of speciation and specialisation, these all helped.  These were all meta-evolutions too.
<h1>Next, Behaviour</h1>
Once more complex brains started appearing, evolution suddenly had a new battleground - behaviour.  By modifying a few genes here and there, the behaviour of an organism could be changed without it necessarily looking any different.  So, exisiting organisms could exploit new ecological niches just by doing things differently.    Behaviours such as building nests, looking after your young, flocking, hiding and hunting are all behavioural adaptations that have stood the test of time.

Even better than that, though, is the behaviour of mimicry.   Develop a sufficiently powerful brain and you can mimic the behaviours of those around you.  Thus, we move to a model in which behaviours (or <a href="http://en.wikipedia.org/wiki/Meme">memes</a>) can exist within a population, transmitted by mimcry (most likely, learning the behaviours of parents).

Advanced mimicry is learning, and learning brains can adapt to their environments and explore new ecological niches.    While other species have spent their time evolving protractile claws, clever camouflage or fast running speed, humans have gone all out on being learners.

Being good at learning means you're great at learning behaviours from others, but also it seems that we have symbolic reasoning abilities enough that we can re-apply ideas learnt in one area to other areas.   In a very hand-waving way, by evolving to be great learners, this has given us the scope to imagine and invent, which are the ways in which we can apply our learning in new situations.
<h1>The Human Change Agent</h1>
Per capita imagination and invention is on the rise.  Two hundred years ago, people had other things to worry about like avoiding being eaten, and doing the hunting and gathering.   Early agriculture (which has been <a href="/2011/09/27/getting-cheaper/">discussed here </a>) was tremendously labour intensive, so that didn't help matters much either.   But, incremental improvements over time in terms of labour-saving devices (such as ploughs first, then motor vehicles, then looms, production lines, robots and so on) have increased the amount of time available to humans to be change agents.

The power of the change agent is greater these days.  New inventions and behaviours propagate a lot more quickly around the planet due to mass media. It is interesting to think of mass media as being a meta-evolution:  it doesn't look like it on the surface, but it is a way of much more quickly propagating successful ideas and behaviours around the planet than there was before.

The internet is the evolution of mass-media.  Whereas in the middle-twentieth century, broadcast was expensive and the preserve of the corporation, the internet reduces the cost of broadcast to near-zero.
<h1>Company Man</h1>
Lots of low-touch industries are now largely automated:  car-production, data centres, grid computing, soon, even <a title="Getting Cheaper" href="http://robmoff.at/2011/09/27/getting-cheaper/">driving</a>.   The two great things about automation are: it does the same thing every time, and, it frees people up to do other things.   This means that a great mega-trend is that people are moving away from the <strong>doing</strong> jobs (following a process for a certain economic outcome) towards jobs of figuring out and then defining what the doing should be.

One hundred years ago when Ford build his cars on the production line, people were cogs in the production machine.   Thirty years ago, the <a href="http://en.wikipedia.org/wiki/Lean_manufacturing">Lean Manufacturing</a> process responds to this by making the human element on the production line responsible too for process improvement.

Nowadays, there are few people even involved in the production process.   Compare this video of the Mercedes line today:

http://www.youtube.com/watch?v=46_rhAzJzo4

With this of the Ford Line a hundred years ago:

http://www.youtube.com/watch?v=S4KrIMZpwCY

If you look at say 3:56 on the first video, you'll see it's a serene environment with a bunch of people in white coats just watching what's happening.  Compare that to 1:26 in the Ford one where a guy is frantically putting wheels together at an alarming rate of knotts.  I expect he will be doing that job again the next day, and the next day (except he probably retired about 70 years ago at least, if he wasn't involved in some tragic industrial accident much earlier).
<h1>Humans are Evolution</h1>
For organisations, services or products to change, currently, they need to engage the human as change agent to apply its unique ability to learn, mimic and invent on their behalf.  This is the last big thing that our products, services and organisations can't do without us.

If you aren't in a job as a change agent, then you're likely to be in a job that is "high-touch" (such as teaching, care, cleaning) or requires a skill that hasn't been automated yet (such as driving, translation, helpdesks).

My advice would be to go for the change agent job (designer, developer, politician, etc.) or, failing that, the high touch job.  If you're in a job doing the same thing, day in, day out, then I think your days are numbered.

In a future article, I will look at how products, services and organisations co-opt the human change agent to evolve themselves.

&nbsp;

&nbsp;

&nbsp;]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>116</wp:post_id>
		<wp:post_date><![CDATA[2012-05-04 14:41:48]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2012-05-04 14:41:48]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[the-human-change-agent]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="category" nicename="singularity"><![CDATA[singularity]]></category>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
			<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_thumbnail_id]]></wp:meta_key>
			<wp:meta_value><![CDATA[129]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_oembed_36dba5d7d2a7f8d11517c843957b861a]]></wp:meta_key>
			<wp:meta_value><![CDATA[<iframe width="500" height="375" src="http://www.youtube.com/embed/S4KrIMZpwCY?fs=1&feature=oembed" frameborder="0" allowfullscreen></iframe>]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_oembed_b3b33f2c66cc50ea10f83b7c6f43cf48]]></wp:meta_key>
			<wp:meta_value><![CDATA[<iframe width="500" height="281" src="http://www.youtube.com/embed/46_rhAzJzo4?fs=1&feature=oembed" frameborder="0" allowfullscreen></iframe>]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_oembed_f465d0c8588f2f0a225d0631621f5ab2]]></wp:meta_key>
			<wp:meta_value><![CDATA[<iframe width="768" height="432" src="https://www.youtube.com/embed/46_rhAzJzo4?feature=oembed" frameborder="0" allowfullscreen></iframe>]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_oembed_time_f465d0c8588f2f0a225d0631621f5ab2]]></wp:meta_key>
			<wp:meta_value><![CDATA[1444426382]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_oembed_648583ff1b02766b115b81e72b4dd4d1]]></wp:meta_key>
			<wp:meta_value><![CDATA[<iframe width="768" height="576" src="https://www.youtube.com/embed/S4KrIMZpwCY?feature=oembed" frameborder="0" allowfullscreen></iframe>]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_oembed_time_648583ff1b02766b115b81e72b4dd4d1]]></wp:meta_key>
			<wp:meta_value><![CDATA[1444426382]]></wp:meta_value>
		</wp:postmeta>
		<wp:comment>
			<wp:comment_id>28</wp:comment_id>
			<wp:comment_author><![CDATA[Lifeforms, Resources and Value : illogicalconclusion]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.robmoffat.co.uk/2012/05/05/lifeforms-energy-and-value/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[178.79.152.8]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-05-05 14:37:14]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-05-05 14:37:14]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] can change and evolve, and so can species.  Although the mechanism to change society is the Human Change Agent, not random mutation and natural [...]]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
				<wp:meta_value><![CDATA[a:4:{s:4:"time";s:15:"1372615778.8107";s:7:"message";s:43:"bobm changed the comment status to approved";s:5:"event";s:15:"status-approved";s:4:"user";s:4:"bobm";}]]></wp:meta_value>
			</wp:commentmeta>
		</wp:comment>
		<wp:comment>
			<wp:comment_id>33</wp:comment_id>
			<wp:comment_author><![CDATA[Evolving the Organisation : illogicalconclusion]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.robmoffat.co.uk/2012/05/22/evolving-the-organisation/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[178.79.152.8]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-05-22 21:30:07]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-05-22 21:30:07]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] In The Human Change Agent, I looked at the idea meta-evolution, and that evolution itself has evolved by the use of layers of abstraction so that it can do it&#8217;s job faster.   Some mechanisms mentioned were: [...]]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
				<wp:meta_value><![CDATA[a:4:{s:4:"time";s:14:"1372615778.786";s:7:"message";s:43:"bobm changed the comment status to approved";s:5:"event";s:15:"status-approved";s:4:"user";s:4:"bobm";}]]></wp:meta_value>
			</wp:commentmeta>
		</wp:comment>
	</item>
	<item>
		<title>Lifeforms, Resources and Value</title>
		<link>http://robmoff.at/2012/05/05/lifeforms-energy-and-value/</link>
		<pubDate>Sat, 05 May 2012 13:50:04 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://www.robmoffat.co.uk/?p=122</guid>
		<description></description>
		<content:encoded><![CDATA[All of the lifeforms on our planet consume resources to survive.  A key one is energy - we all need that to keep moving.  But, we also need vitamins, minerals and whatnot to actually build our bodies with.  We also deploy our resources in order to accumulate more.   For example, an animal going out foraging will use energy doing so, but it hopes to eat enough to make that worthwhile.

If a species expends more resources every day than they bring in, then they're history.   Of course, lots of animals like bears and migratory birds have long periods where they expend more than they consume, but they have to "save up" before hand - nature doesn't do loans.

<!--more-->

So, when a phenotype expends energy on an activity (say, hunting or grazing), it has the expectation that that activity will pay back more energy later.  This is <strong>value, </strong>and it's the same concept as we have for spending money - when we do, we want to get back value.  That is, the benefit we get back from the money spent is greater than the outlay in the first place.

For most species in the world, this is fairly dog-eat-dog:  you've got to protect the energy you've got while grabbing as much energy from everywhere else as possible.   But there are other ways.
<h1>Symbiosis</h1>
The pilot fish is a great example of the other way: it is involved in a trade with a shark (ray, whatever):  in return for protection, it keeps the host animal clean.  Both sides expend energy , but both gain more benefit back from the arrangement.  There is a net creation of value.

Symbiosis is what humans do.  In spades.   We're not specialists in the same way as pilot fish (i.e. the whole species playing the same game), but we are specialists within-species.  This means that there is a symbiotic relationship between me and the window cleaner.   I give him money to clean my windows because we both get value from this arrangement (he puts dinner on the table, I get my windows cleaned for a lot less effort than I could do it myself).

Thinking about this at the whole-economy level might be quite tricky.  But luckily, it works at every level.   If the world consisted of just two guys, one who was good at fishing, the other who was good at farming, they could both create value by sticking to their individual specialities and swapping some of their produce.  It would work out a lot better than each trying to do a bit of both.
<h1>Value Reframed</h1>
Porter's <a href="http://en.wikipedia.org/wiki/Value_chain">Value Chain</a> seminally framed value within the organisation as a function of change in money, but I hope this article goes further to reframe value in terms of life:  a species is successful if it can accumulate resources rather than lose them.  Now, you might argue that the two individuals, above, fishing and farming, don't need each other - if they do their jobs well enough, they are both going to get enough energy and survive.

However, resources are a bit more complex than that - we don't just need energy, we need lots of different nutrients, so eating a balanced diet means you live longer and better.

This is a lot like the <a href="http://en.wikipedia.org/wiki/Homo_economicus">Homo Economicus</a> idea... of humans as a species specialising and tranding amongst themselves to maximise value, so let's just move onto
<h1>Value and Law</h1>
The symbiotic approach is engrained in human behaviour and really represents what society is about.   For example, from a value perspective, stealing makes a lot of sense: taking someone else's food might take very little energy, but pay big returns.     It happens all over the place in the natural world, and it's just what happens.

However, as humans, we frown on this.  In fact, the symbiotic approach is the only approach we condone:  theft is out.  Also, if you sell a product, it should benefit both the buyer and the seller, otherwise it's kind of still theft.

What happens if you stray from the path of symbiotic value creation?  The weight of society will bear down on you and impose it's own sanctions:  we try and catch thieves, we prosecute people selling rip-off products, we have consumer groups, laws to protect buyers against dishonest sellers, etc. etc. etc.

It obviously gets a bit more complex when a third party loses out.   For example, oil producers generate value for car drivers by making and selling petrol.  However, they damage the environment a bit, which affects everyone and no one is paying for it.  It's almost like the buyer and the seller are doing a little bit of stealing from the rest of us each time they make a transaction.

So, the takeaway from this is that you, your service, your product, need to engage in symbiotic value creation to be allowed to operate in society.

But why does society force us to do this?

This might be a tautological question - it's kind of the definition of society in the first place.   So the question might be, why do we have society?  Here is the answer:  the net amount of value created by agents operating within a society is greater than the net amount of value of the same agents operating without the society.
<h1>Society and Value</h1>
In the same way as species need to be net value creators, so do societies, otherwise, they'll fall apart and people will prefer anarchy.      There are a number of parallels here:
<ul>
	<li>Societies are a common set of rules and behaviours, so are species</li>
	<li>Societies have to be net generators of value, so do species</li>
	<li>Societies can change and evolve, and so can species.  Although the mechanism to change society is the <a title="The Human Change Agent" href="http://robmoff.at/2012/05/04/the-human-change-agent/">Human Change Agent</a>, not random mutation and natural selection.</li>
</ul>
One way of looking at society then, is that it is also a type of life form.

So if you wish to exist within it, you need to help society improve it's net value, otherwise you'll be treated as something hostile...

&nbsp;

&nbsp;

&nbsp;

&nbsp;

&nbsp;

&nbsp;

&nbsp;]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>122</wp:post_id>
		<wp:post_date><![CDATA[2012-05-05 13:50:04]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2012-05-05 13:50:04]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[lifeforms-energy-and-value]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="category" nicename="general"><![CDATA[general]]></category>
		<category domain="category" nicename="singularity"><![CDATA[singularity]]></category>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
			<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_thumbnail_id]]></wp:meta_key>
			<wp:meta_value><![CDATA[127]]></wp:meta_value>
		</wp:postmeta>
		<wp:comment>
			<wp:comment_id>29</wp:comment_id>
			<wp:comment_author><![CDATA[Profit, Efficiency and Time : illogicalconclusion]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.robmoffat.co.uk/2012/05/11/profit-efficiency-and-time/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[178.79.152.8]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-05-11 08:36:53]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-05-11 08:36:53]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] In Lifeforms, Resources and Value I looked at the idea that some lifeform, whether a species, society, company or individual must capture value.   That is, they must see a net gain in resources from their activities.   If I am fishing to catch food to live, I must spend less energy and other resources on the act of fishing than I get back from doing it, otherwise it&#8217;s not worth my while. [...]]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
				<wp:meta_value><![CDATA[a:4:{s:4:"time";s:15:"1337158280.8788";s:7:"message";s:43:"bobm changed the comment status to approved";s:5:"event";s:15:"status-approved";s:4:"user";s:4:"bobm";}]]></wp:meta_value>
			</wp:commentmeta>
		</wp:comment>
		<wp:comment>
			<wp:comment_id>31</wp:comment_id>
			<wp:comment_author><![CDATA[Examining The Change Agent : illogicalconclusion]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.robmoffat.co.uk/2012/05/13/157/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[178.79.152.8]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-05-16 08:26:08]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-05-16 08:26:08]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] is this blog, we have addressed the concept of value with respect to evolution.   Let&#8217;s look again at the two key processes of [...]]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
				<wp:meta_value><![CDATA[a:4:{s:4:"time";s:15:"1337158272.3629";s:7:"message";s:43:"bobm changed the comment status to approved";s:5:"event";s:15:"status-approved";s:4:"user";s:4:"bobm";}]]></wp:meta_value>
			</wp:commentmeta>
		</wp:comment>
		<wp:comment>
			<wp:comment_id>34</wp:comment_id>
			<wp:comment_author><![CDATA[Evolving the Organisation : illogicalconclusion]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.robmoffat.co.uk/2012/05/22/evolving-the-organisation/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[178.79.152.8]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-05-22 21:31:10]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-05-22 21:31:10]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] Popular Posts       [...]]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
				<wp:meta_value><![CDATA[a:4:{s:4:"time";s:15:"1372615778.7623";s:7:"message";s:43:"bobm changed the comment status to approved";s:5:"event";s:15:"status-approved";s:4:"user";s:4:"bobm";}]]></wp:meta_value>
			</wp:commentmeta>
		</wp:comment>
	</item>
	<item>
		<title>Best Cash Out Quick</title>
		<link>http://robmoff.at/2012/05/09/best-cash-out-quick/</link>
		<pubDate>Wed, 09 May 2012 14:47:40 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://www.robmoffat.co.uk/?p=133</guid>
		<description></description>
		<content:encoded><![CDATA[Facebook is going IPO.   So what are shareholders actually buying?

When a company has an IPO, do investors expect to get a piece of the company as it was, or as it will be?   IPO'ing affects the way a company behaves - it now has to produce financial statements in accordance with the stock market it is listed on.  It also has to think about share price and keeping shareholders happy.<!--more-->

Now, in the case of Facebook, Mark Zuckerberg will still control over 50% of the company after the IPO.  This means that, theoretically, he doesn't have to keep shareholders happy.  This is probably an illusion.  If he decided that Facebook was going to "pivot" and sell online knitwear instead of being a social network, I'm pretty sure that he would somehow be evicted from the post.

Also, there will be a lot of people within the company looking to maximise the value of the shares they own.

Going IPO is something of a pair of handcuffs:  keeping shareholders happy does matter.  But sadly, shareholders both lack individual vision  (they just want more of the same) and also long term commitment to a company.  This forces you to stick to the knitting (or, er, in this case, not) and look only a year ahead in your forecasts.

So taking Facebook public is a risky business:  on the one hand, you're going to stifle evolution within the company.  On the other, you are improving its capital position, which allows it to do things like buying in innovation (Instagram, anyone?).
<h1>Facebook's Evolution</h1>
So a great question is - how to evolve Facebook  further?   They have already captured 1 billion people's address books, likes, dislikes, comments and photos.  Where would they go from here?     Here are some issues:
<h2>Data likes to be free.</h2>
The social graph that they have built up could be anyones after they suffer their first sucessful hack.  What would this mean to another company building a social network, or a product that requires social data?  Also, the privacy concerns this raises really should have given pause already to people just randomly sharing everything about themselves on Facebook.  Maybe we'll wake up soon.
<h2>Their big data isn't all that big</h2>
The amount of current, relevant information they have could probably fit on a few hard disks today.   Adjust for Moore's law and it could be on a memory stick in a few year's time.

Part of Facebook's success has been due to building impressive data centres and handling massive amounts of traffic.  But whereas the amount of data Google is dealing with is growing exponentially, the number of people on the planet is growing at a decelerating rate.  As computing power increases, the effort in building a Facebook infrastructure is going to come right down.
<h2>Market share is captured more and more quickly.</h2>
Taking 10 years to get to 1 billion users seems cool now, but in a few years' time, this will seem slow.  I'm not saying necessarily that another social network will come along and unseat Facebook, but given that what they have accomplished will seem more and more trivial with time, it's likely that a new disruption will appear before long and make Facebook meaningless, in much the same way as no one buys tape-to-tape machines anymore.

So, given these forces, perhaps now is the right time to be cashing out:  today's wildly profitable and successful idea is tomorrow's turkey, as <a href="http://www.theatlanticwire.com/technology/2012/05/decline-and-fall-draw-something/51792/">Zynga</a> are just finding out.

In conclusion - Facebook is a wildly profitable company at the moment, but after IPO, change is going to get harder for them.   When they are no longer solving a "hard problem", they're going to get disrupted.

&nbsp;]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>133</wp:post_id>
		<wp:post_date><![CDATA[2012-05-09 14:47:40]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2012-05-09 14:47:40]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[best-cash-out-quick]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="category" nicename="information-theory"><![CDATA[information theory]]></category>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
			<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_thumbnail_id]]></wp:meta_key>
			<wp:meta_value><![CDATA[137]]></wp:meta_value>
		</wp:postmeta>
	</item>
	<item>
		<title>Evolving the Organisation</title>
		<link>http://robmoff.at/2012/05/22/evolving-the-organisation/</link>
		<pubDate>Tue, 22 May 2012 21:30:04 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://www.robmoffat.co.uk/?p=147</guid>
		<description></description>
		<content:encoded><![CDATA[In<a title="The Human Change Agent" href="http://robmoff.at/2012/05/04/the-human-change-agent/"> The Human Change Agent</a>, I looked at the idea meta-evolution, and that evolution itself has evolved by the use of layers of abstraction so that it can do it's job faster.   Some mechanisms mentioned were:
<ul>
	<li>Chemical evolution</li>
	<li>Standardized genetic alphabet (i.e. DNA, RNA)</li>
	<li>Cellular life</li>
	<li>Multicellular life</li>
	<li>Behavioural Evolution</li>
	<li>Societal Evolution</li>
</ul>
We can see in the above, how nature has evolved layers of <em>abstraction</em> (chemistry is at a low level, behaviour and society at a higher level), used in roughly the same way as software developers do:  we can develop software faster by using the lower level abstractions that came before (e.g building websites uses high-level languages, operating systems, web servers that already exist).

Some of these levels would also (to a software engineer) be called <em>encapsulation</em>. For example, a multi-cellular creature encapsulates many millions of individual cells.  A cell encapsulates lots of <a href="http://en.wikipedia.org/wiki/Organelle">organelles</a> (such as mitochondria, plastids, flagella).   A society encapsulates people to a greater or lesser extent.

Then in<a title="Lifeforms, Resources and Value" href="http://robmoff.at/2012/05/05/lifeforms-energy-and-value/"> Lifeforms, Resources and Value</a> I considered how evolution was about a constant struggle to capture value, and that societies represented a new type of value-capturing life form.  Through the use of law, they allowed the individuals within the society to capture more value than they could on their own.

Societies,  as they are at a higher level of abstraction and encapsulation than us, evolve faster than we do.  (Consider that humans have been around for about <a href="http://en.wikipedia.org/wiki/Human">200,000</a> years, democracy for <a href="http://en.wikipedia.org/wiki/History_of_democracy">2,500 </a>years.
<h1>Living Societies</h1>
So, we can see that societies are evolving.  But do they count as a life form?  I would argue that if single-celled bacteria are considered alive, then so should society be:  it has the same self-sustaining and signalling processes as other living things.  Arguably, since it is composed of living, biological entities, it might even count as biological life, but we needn't go that far.

If societies are indeed life forms, then they have to face the same evolutionary pressures as other life forms:  they need to capture value (resources) in order to survive, and they are in competition with other societies for the same scarce resources.    Successful societies subsume less successful ones (through wars or annexing, perhaps).  Less successful societies die out: their populations either emigrate or they collapse for some reason.

Here are some ways in which the society life-form is apparent in the everyday world:
<ul>
	<li><strong>Laws are set, and people go to prison:  </strong> Being in prison is a detriment to the person involved, but a benefit to society as a whole.  Society is happy to pay for the imprisonment.</li>
	<li><strong>Most countries have border controls:  </strong> This is a detriment to every individual, since the individual would rather be allowed to go where he or she wants.  However, society is deemed to gain either by keeping certain people out, or keeping people in, as this preserves the society against change.</li>
	<li><strong>Innovation is encouraged: </strong>If I invent a new gizmo that saves everyone time and money, but puts a hundred of people out of work, I am a champion of society.  But, if I kill one hundred people, I would be <a href="http://homesecurity.net/serial-killers/">one of the worst serial killers ever</a>.  Now, obviously, killing people is not the same as putting them out of work, but either way, I've not done them any favours.  But society has gained in the former case and lost in the latter.</li>
</ul>
<h1>Competing Societies</h1>
Different societies have different values, and these reflect the histories and backgrounds of the people within them.  In the UK, we have a strong socialist streak:  we believe in the idea of free healthcare for all, and social security (both introduced after the Second World War).

Is there an evolutionary argument for this?   Perhaps, and perhaps not.  Not all countries in the world share our values.  Some are more socialist, some are less.

I would argue that where a society is more socialist, it focuses more on caring for the constituent humans within itself.  Where it is less socialist, it focuses more on creation of societal value.

For example:  should society care for a terminally sick person?  This is a question for society.  In the UK, we say that yes, society should take on this burden.  Often family will be around to shoulder most of this burden, but if they are not, it will be taken on by social services or healthcare workers.  <em>To a greater or lesser extent, anyway.</em>

Other societies may feel differently, and adopt a different approach: this is all well and good.  The process of evolution challenges us to explore different <strong>permutations, </strong>after all.   It also enforces a <strong>selection</strong> process:  we don't have societies that enforce that everyone over the age of 10 should be executed, for example.  That society wouldn't last long and would not generate much value.   We don't have Mongol hordes anymore, or Viking raids.  Those ideas have been selected out too.  In fact, traveller communities are being eradicated in the UK - that's a type of society that's not really working out anymore.
<h1>Which Societies Survive?</h1>
So, what does a society need to do to avoid negative selection?  Clearly, the same thing as any life-form:  be more efficient at generating value than its rivals.   This explains why modern societies encourage innovation - because this is a powerful tool in efficient value creation.

This also explains why governments are so obsessed with GDP figures:  GDP is a reflection of value creation within a society, and as good a measure of the health of the society-as-life-form as you can get.

So, the socialist dilemma is this:  on the one hand, society should exist to serve the people within it.  But, on the other hand, societies should be trying to capture as much value as possible.  At the moment, this is not much of a dilemma:  Providing healthcare and social security <strong>increases</strong> the overall value creation of the society, because it stops useful people from dying from curable diseases or lack or work.  Additionally, we can see first hand that socialism is obviously a beneficial trait for a society to have - all societies on the globe exhibit some socialism to a greater or lesser degree.

The real dilemma is in the future.
<h1 style="text-align: left;"><a href="http://robmoff.at/2012/05/22/evolving-the-organisation/dilemma/" rel="attachment wp-att-189"><img class="size-full wp-image-189 aligncenter" title="dilemma" src="http://robmoff.at/wp-content/uploads/2012/05/dilemma.png" alt="" width="480" height="156" /></a></h1>
<h1 style="text-align: left;">But what will happen in the future?</h1>
If we accept the argument presented in<a title="The Human Change Agent" href="http://robmoff.at/2012/05/04/the-human-change-agent/"> The Human Change Agent</a>, then we are expecting that over time, less and less of humanity will be in a position to capture value.  Machines, computers, robots: these things will be better at capturing value than we are.

Eventually, the resources consumed by humans will make them no-longer cost effective:  we will be using up more natural resources than we create for our societies.

What will our societies do then?   If they are in competition with one another, then the societies that decide to ditch humans will out-compete the more benevolent societies that look after their populations.

This is a fairly depressing sounding outcome:  it sounds like we are all doomed.  However, there are two possible ways in which this fate can be avoided, which I will discuss in a future article.

&nbsp;
<p style="text-align: center;"></p>]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>147</wp:post_id>
		<wp:post_date><![CDATA[2012-05-22 21:30:04]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2012-05-22 21:30:04]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[evolving-the-organisation]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="category" nicename="singularity"><![CDATA[singularity]]></category>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
			<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_thumbnail_id]]></wp:meta_key>
			<wp:meta_value><![CDATA[197]]></wp:meta_value>
		</wp:postmeta>
	</item>
	<item>
		<title>Profit, Efficiency and Time</title>
		<link>http://robmoff.at/2012/05/11/profit-efficiency-and-time/</link>
		<pubDate>Fri, 11 May 2012 08:36:50 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://www.robmoffat.co.uk/?p=149</guid>
		<description></description>
		<content:encoded><![CDATA[In<a title="Lifeforms, Resources and Value" href="http://robmoff.at/2012/05/05/lifeforms-energy-and-value/"> Lifeforms, Resources and Value</a> I looked at the idea that some lifeform, whether a species, society, company or individual must capture value.   That is, they must see a net gain in resources from their activities.   If I am fishing to catch food to live, I must spend less energy and other resources on the act of fishing than I get back from doing it, otherwise it's not worth my while.
<h1>Profit</h1>
In business, this is called turning a profit.  If I engage in an unprofitable fishing trip, then I end up dipping into any reserves of energy that I might be carrying.   It's the same with companies - if they don't make the sales, they will expend their free cash to keep going.

But profit on it's own tells us nothing:  if a company is using vast reserves of energy, but only making a slight profit, an economist would say that it is not providing an adequate return on capital employed (ROCE).   This is effectively a measure of the efficiency with which a company or life-form is operating.
<h1>Efficiency</h1>
Efficiency has upsides as well as down-sides.  The big upside of efficiency is that it allows you to grow.  An efficient species captures more resources than it's competitors.  These resources are spent by a species on growing the population.   The reason that growing your population is a good idea is that it spreads the risk of extinction amongst a larger group, and it also means that you are doing more evolution (each phenotype has a unique genetic code, therefore exploring more genetic possibilities).

So the great thing about being an efficient organism (in comparison to rivals) is that, within a given period of time, you get to evolve faster, and therefore potentially be even more efficient.

There is a downside of efficiency, though.   Usually, efficiency means specialisation: that is, doing a particular job extremely well.  The problem is that the evolutionary landscape changes all the time with the evolution of other new ideas and species.   So while it's possible to be extremely efficient at one moment, you can suddenly find the rug swept from under your feet at the next.

Humans are not a very efficient species.  In fact, mammals generally are not.  Being warm-blooded uses up a lot of energy, and having large brains uses up energy too.   Lizards can live in much more inhospitable conditions than us, eating rarely and drinking little.    We have traded genetic efficiency at exploiting a niche for our flexibility to adapt to lots of different conditions.   Arguably, as the pace of evolution has increased, this has become more and more the best strategy -  it has been better to be able to flexibly adapt to current conditions than to be completely efficient.

So this represents a tradeoff:  efficiency is something to be aimed for, as it gives you more scope to evolve, but at the same time, you need to preserve adaptability to that you can cope with the changing competitive environment.
<h1>Time</h1>
Time, as Einstein pointed out, is relative.   On a species level, time can be viewed as a resource required for evolution:  if you don't evolve, you will be left behind and out-competed.   However, for an individual in a species, time for evolution translates to time for reproduction, which is fairly much the same thing.

For humanity, there is a great trade-off with lifespan:   longer-lived individuals are much, much better at competing than younger ones.  This is because it takes so long to learn the ropes.   This seems to be irrespective of the actual length of our lives.  As we have grown to live longer, the amount of time we spend in education has risen and risen (see <a title="Getting Cheaper" href="http://robmoff.at/2011/09/27/getting-cheaper/">Getting Cheaper</a>).

But living longer means you are doing less actual genetic evolution - species with shorter reproductive cycles evolve faster.

Mammals generally, but humans in the extreme have adapted to this tradeoff by looking after their young for long periods.   We tend to have three or four generations alive at a time, with the most able generations caring for the younger ones.  That way, our memes are passed from one generation to the next efficiently and completely.

We have sacrificed a lot of our ability to evolve genetically for ability to evolve memetically.
<h1>Never Enough Of It</h1>
Problem is, we're not the only ones evolving.  As discussed in<a title="The Human Change Agent" href="http://robmoff.at/2012/05/04/the-human-change-agent/"> The Human Change Agent</a>, we are now evolving at a societal, product, or organisational level.  The pace of this evolution is much faster - our products and organisations are evolving much more quickly than we are.

Because as humans we are caught up in this evolutionary cycle, our perception of time is altered by it.  The race to enter a market might be six months to a year, pushing reforms through parliament to adapt to the changing world might need to be done in months.   Reacting to changes in the markets might need to be done in hours.

This is why a lot of people are so busy now:  we are the change agents of an organisational evolution which is happening so fast that we struggle to keep up.  No wonder our in-boxes are so full.

&nbsp;

&nbsp;]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>149</wp:post_id>
		<wp:post_date><![CDATA[2012-05-11 08:36:50]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2012-05-11 08:36:50]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[profit-efficiency-and-time]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="category" nicename="singularity"><![CDATA[singularity]]></category>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
			<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_thumbnail_id]]></wp:meta_key>
			<wp:meta_value><![CDATA[151]]></wp:meta_value>
		</wp:postmeta>
	</item>
	<item>
		<title>Examining The Change Agent (part 1)</title>
		<link>http://robmoff.at/2012/05/13/157/</link>
		<pubDate>Sun, 13 May 2012 21:13:18 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://www.robmoffat.co.uk/?p=157</guid>
		<description></description>
		<content:encoded><![CDATA[Let's look at the way humans and natural selection both create evolutionary processes.  Both of these have two key parts:
<ul>
	<li><strong>Permutation:</strong> Creating different versions of an existing successful pattern.</li>
	<li><strong>Selection:</strong>  Choosing the patterns that capture the most value, and moving forward with them.</li>
</ul>
<!--more-->In nature, the first stage, permutation, is done by reproduction, and child-rearing.  This is where a phenotype is effectively creating inexact duplicates of itself.  The second step, selection, is done by the environment, which, through the process of survival-of-the-fittest means that by and large, the phenotypes creating value will live on.

For a business improving a product, things are slightly different, but the process still involves permutation and selection.  The diagram below shows how this works:
<p style="text-align: left;"><a href="http://robmoff.at/2012/05/13/157/cg_white/" rel="attachment wp-att-168"><img class="aligncenter wp-image-168 size-large" title="cg_white" src="http://robmoff.at/wp-content/uploads/2012/05/cg_white-590x502.png" alt="" width="590" height="502" /></a><a href="http://robmoff.at/2012/05/13/157/evo-2/" rel="attachment wp-att-162">
</a>On both sides of the diagram, start at A.  This is an existing product, gene, species, whatever: it's the thing that's going to evolve.  On the left side, it's evolving through natural selection, and new permutations are created (0..n of them).  Then, the process of selection occurs to give us B (chosen)... then the cycle repeats.</p>
<p style="text-align: left;">On the right side, we can see how this differs where evolution co-opts a human change agent.  Start with A again.   The first thing the human change agent does is to model A internally.  This is a learning process.  It could mean, understanding how a product works, or how a political system works, or whatever.</p>
<p style="text-align: left;">The next step is where the human, having built an internal model, then plays with it:  "Wouldn't it be good if...", "What about if it had an extra....", "How would it look if we did...".   Each of these is an permutation of the original model, which changes it in a given way.   By mentally performing these permutations, knowingly or not, we identify the deficiencies in A and ways to improve it.</p>
<p style="text-align: left;">Some of these would be terrible ideas.  Our brains do their best to filter these.  Often without us even realising it. Next time you're struggling to use a product, you might find that the ways in which it could be improved will just pop into your head, apparently out of nowhere.</p>
<p style="text-align: left;">I would contend that this has happened because of a process like the one above:  your brain has developed a model of the product, and then iterated around lots of different, incrementally different versions of that same model.  Somewhere else in your brain, the versions that make no sense have been rejected.  The ones that make sense are bubbled up into your conscious brain.</p>
<p style="text-align: left;">In the diagram, these become "C chosen" ideas.   The reason your consciousness needs to know about them is that now you need to implement that change, and turn A into B, before you go round again.</p>

<h1 style="text-align: left;">Introducing Value</h1>
Elsewhere is this blog, we have addressed the concept of <a title="Lifeforms, Resources and Value" href="http://robmoff.at/2012/05/05/lifeforms-energy-and-value/">value</a> with respect to evolution.   Let's look again at the two key processes of evolution:
<ul>
	<li><strong>Selection:</strong>  The selection process is a weighing mechanism.  It is basically saying - does this (species, product, gene, lifeform) add value?  That is, given the resources it consumes, does it get more back by its activities?    Those lifeforms that don't manage this, don't get selected for further evolution, and they leave the game.</li>
	<li><strong>Permutation:</strong>  This is a process in which accumulated value is expended to produce more versions of the lifeform.   The more value a lifeform has produced, the more evolution it gets to do by this approach.</li>
</ul>
&nbsp;

In a resource-unconstrained universe, only <strong>permutation</strong> would be needed for us to see natural selection working.  We would definitely end up with more fitter lifeforms than unfit ones, because unfit ones would never have collect the resources to permute.

However, we live in a resource-constrained place, so nature conspires to remove the unsucessful lifeforms to make way for newer, more successful ones.
<h1>Behaviour and Value</h1>
<p style="text-align: left;">Value becomes more complex on the right hand side of the diagram, when we consider how this would need to work for humans (and other behaviour-centric evolving life-forms).  Rather than coming pre-programmed with a set of behaviours, we adapt over time.  This means we need a mechanism of <strong>selection</strong> that doesn't involve us dying in order to get us to change our behaviours.</p>
<p style="text-align: left;">For this, we have evolved our own value judgement mechanism based on feelings like happiness and sadness.  This sounds like a big leap, but let's explore the idea of emotions further and see how this fits in.</p>
<p style="text-align: center;"><a href="http://robmoff.at/2012/05/13/157/cg_white-2/" rel="attachment wp-att-178"><img class="aligncenter wp-image-178 size-full" title="Behavioural Evolution" src="http://robmoff.at/wp-content/uploads/2012/05/cg_white1.png" alt="" width="420" height="336" /></a></p>
<p style="text-align: left;">In the diagram above, we have a model of behaviours evolving within an ecosystem.   Start at the box on the bottom right:  a creature is exhibiting a behaviour (A) which other creatures can observe and copy.   The permutation process is exactly that - other creatures observe the behaviour and copy it for themselves, creating A'.   In the process, the behaviour would be copied inexactly - no two creatures would do it the same way.</p>
<p style="text-align: left;">So, other creatures develop their own models of the behaviour, which they can then try out.   And here lies the rub:   Those creatures need to be able to evaluate these behaviours (the selection process) and decide for themselves which ones work and which ones don't.</p>
<p style="text-align: left;">In order to do this, they need an internal value measurement system, which would need to work like this:</p>

<ul>
	<li>I exhibit behaviour A'</li>
	<li>I receive a reward (or otherwise)</li>
	<li>I associate the reward with the behaviour.</li>
	<li>I evaluate whether this reward-behaviour  causality is worth repeating.</li>
</ul>
<p style="text-align: left;">Our brains are attuned to recognise rewards through chemical reinforcers:   when we exhibit a behaviour, and get a reward, somehow, the behaviour itself is rewarded.  This is effectively <a href="https://en.wikipedia.org/wiki/B._F._Skinner">Skinnerian</a> operant conditioning.</p>
<p style="text-align: left;">As well as rewards, we also recognise penalties.   If a behaviour leads us to get hurt, this also generates a stream of emotions, which negatively feeds back on the behaviour.</p>

<h1 style="text-align: left;">On Permutation</h1>
<p style="text-align: left;">The <strong>permutation</strong> box in the diagram above conceals a wealth of complexity, though.   The process of rewards and feedback has been well researched over the years (although we still don't completely understand all the complexities of the process, or even why it is so complex).  However, the process of mimicry in nature is, if anything, more complex.</p>
<p style="text-align: left;">More to come in part 2.</p>
<p style="text-align: left;"></p>]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>157</wp:post_id>
		<wp:post_date><![CDATA[2012-05-13 21:13:18]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2012-05-13 21:13:18]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[157]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="category" nicename="information-theory"><![CDATA[information theory]]></category>
		<category domain="category" nicename="management"><![CDATA[management]]></category>
		<category domain="category" nicename="singularity"><![CDATA[singularity]]></category>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
			<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_thumbnail_id]]></wp:meta_key>
			<wp:meta_value><![CDATA[171]]></wp:meta_value>
		</wp:postmeta>
		<wp:comment>
			<wp:comment_id>32</wp:comment_id>
			<wp:comment_author><![CDATA[Examining The Human Change Agent (part 2) : illogicalconclusion]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.robmoffat.co.uk/2012/05/20/examining-the-human-change-agent-part-2/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[178.79.152.8]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-05-20 20:17:54]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-05-20 20:17:54]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] the previous episode, we looked at the evolutionary process as a way of maximising value. It consists of two [...]]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
				<wp:meta_value><![CDATA[a:4:{s:4:"time";s:14:"1337545281.011";s:7:"message";s:43:"bobm changed the comment status to approved";s:5:"event";s:15:"status-approved";s:4:"user";s:4:"bobm";}]]></wp:meta_value>
			</wp:commentmeta>
		</wp:comment>
	</item>
	<item>
		<title>Examining The Human Change Agent (part 2)</title>
		<link>http://robmoff.at/?p=185</link>
		<pubDate>Sun, 20 May 2012 20:17:51 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://www.robmoffat.co.uk/?p=185</guid>
		<description></description>
		<content:encoded><![CDATA[In the <a title="Examining The Change Agent (part 1)" href="http://robmoff.at/2012/05/13/157/">previous</a> episode, we looked at the evolutionary process as a way of maximising value. It consists of two steps:

<strong>permutation</strong> - where variations upon the original pattern are considered

<strong>selection</strong> - where the fittest patterns are kept and the  least fit are discarded.

As species have evolved in complexity, some of this evolutionary process has been internalised.    <strong>Permutation</strong> in humans comes to mean observing, duplicating and modifying behaviour.  <strong>Selection</strong> is where we keep the behaviours that reward us the most.

This means that instead of hard-coding behaviours as part of our genetic pattern, we instead hard-code only the rewards, and leave humans to individually evolve towards achieving these rewards.   What are the rewards?
<ul>
	<li>Drinking when we are thirsty (and avoiding thirst)</li>
	<li>Eating when we are hungry (and avoiding hunger)</li>
	<li>Looking for happiness</li>
</ul>
... and so on.   Basically, behaviours that make us fulfilled and happy.  Now obviously, there is a drawback to this: since the goals and rewards are genetically evolving fairly slowly by Darwinian methods , but our behaviours are evolving much faster memetically, they can get left behind.

No one would deny that there is an obesity epidemic:  the reason for this is, we like to eat to excess.   This is an evolved response - hundreds of years ago, eating to excess was a good idea, because you never knew when your food supply might be interrupted.   Now, that's less of a concern than heart disease.

So, it's not a perfect system.   We are trying to evolve our behaviour to maximise value, but we are actually evolving behaviour to maximise a proxy of value, and if the proxy doesn't actually represent what's best for us, we behave in ways which are bad for us.  Often, even when we <span style="text-decoration: underline;">know</span> they are bad for us.
<h1>More on Permutation</h1>
Copying and stealing genes has long been a good idea.  Although mammals rely only on sexual reproduction, bacteria and plants often share genetic material widely.  It makes a lot more sense than doing all the evolving yourself.  The same is true of behaviour, and the process of copying is mimicry.   Once you have mimicry down pat, the memetic evolution can really pick up steam.  Before that, you would have to evolve all your behaviours yourself.

For this reason, understanding how mimicry works is pretty much key to understanding how humans work.

&nbsp;

&nbsp;]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>185</wp:post_id>
		<wp:post_date><![CDATA[2012-05-20 20:17:51]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2012-05-20 20:17:51]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[examining-the-human-change-agent-part-2]]></wp:post_name>
		<wp:status><![CDATA[draft]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="category" nicename="singularity"><![CDATA[singularity]]></category>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
			<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
	</item>
	<item>
		<title>Escaping Our Fate</title>
		<link>http://robmoff.at/?p=200</link>
		<pubDate>Mon, 01 Jul 2013 09:43:13 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://www.robmoffat.co.uk/?p=200</guid>
		<description></description>
		<content:encoded><![CDATA[Let's take for granted the arguments in<a title="Evolving the Organisation" href="http://robmoff.at/2012/05/22/evolving-the-organisation/"> this article</a>: namely, that soon, each society will have to make a choice between expending energy looking after humans, or maximising value creation.

Previously, these two things had gone hand in hand:  humans possessed skills that were unavailable elsewhere in the ecosystem, and were therefore a scarce resource.   However, if the world is increasingly mechanised to the point that humans are no longer useful, humans will actually be a drain on the resources of the society they are in.

This hasn't happened yet.  But, if (when?) we begin to live in a world where unemployment is the norm rather than the exception, then we can probably argue that this has started to happen.

In the previous article, I said there were two ways out of this fate.   Let's start by looking at some potential ways out which probably won't work:
<h2>"The French Choice"</h2>
Looking abroad at the recent results of the French general election (2012), I would say that the voters there had voted against competitive society.  That is, they voted for a leadership to focus society more on the citizens than on being competitive.    So, I am going to say that a society that tries to preserve it's way of life against evolution is The French Choice.

Would the French Choice Work?  I would say that adopting this pose unilaterally isn't going to work.  The problem is that in the history of the world, more advanced civilisations have always subjugated weaker ones.  European colonialisation of the Americas, Australia, Africa and so on are an example.  Many people point to these events as being barbaric and genocidal.  And they were.    The problem is, to avoid the genocide of colonising the Americas, all of the colonial powers would have had to agree <em>not to do it</em>.

Remember that the colonies were all in competition with each other, fighting wars over this piece of land or that.  They didn't trust each other one jot, and so there was really no possibility of ever agreeing not to colonise other countries - these genocides were practically built in to the competitive landscape.

This doesn't make them right.  But remember that <em>right </em>is something that is defined by society anyway:  in a state of anarchy, there is no good or evil, there is just survival of the fittest.   The colonial powers involved just acted according to what was in their best interests.

So, the French choice would mean turning your back on competitivity.  Eventually, your society would be left behind, and the advanced civilisations would compete over taking your resources...just as is in nature for all life-forms.
<h2>Global Agreement...</h2>
What if all of the nations in the world agreed to cap progress at a given level, a bit like the <a href="http://en.wikipedia.org/wiki/Amish">Amish</a>?    Can you turn back the clock?  Or even stop it?  Once the genie is out of the lamp, can it be put back in?  In Dune, Frank Herbert envisages a future where computers have been banned <a href="http://en.wikipedia.org/wiki/Butlerian_Jihad">due to this scenario</a>.  It made space travel much more tricky (and drug-prone) but they had a lot of fun with sand-worms and stuff.

Could that work?   Currently, this looks unlikely.  Technology improves by gradualism, so it would be difficult to define exactly where the stopping point was.  Anyone using outlawed technologies would have an advantage over others.      But the main problem is the same as that faced by climate agreement:
<blockquote>Getting all of the world to agree to do something which is collectively beneficial, but individually detrimental.</blockquote>
If we can't agree to stop polluting the planet to save ourselves, what chance to be have of stopping ourselves using technologies?

That might sound like an overly pessimistic world-view.  But there is a evolutionary argument underpinning this: in order to evolve, societies have to all strive to be different, since <strong>permutation</strong> is one of the<a title="Examining The Change Agent (part 1)" href="http://robmoff.at/2012/05/13/157/"> two key parts of evolution</a>.     Technological change is one of the ways in which we create this difference.  So what we are saying is that in order to stop societies from heading down a value maximising rather than humanity maximising route, we need them to stop evolving.
<h2>... Or Global Society?</h2>
As we have seen, evolution uses abstraction as a tool.   Society is currently a top-level abstraction, but in the future, a global super-society might become a higher level abstraction.  If this occurred, we could expect to see societies having to act in ways that were only value-creating for the planet as a whole.  This would mean an end to behaviours that are essentially theft:  where one society does something at the expense of another (e.g. war, annexation, pollution) and has to move to a symbiotic societal level (<a title="Lifeforms, Resources and Value" href="http://robmoff.at/2012/05/05/lifeforms-energy-and-value/">just as intra-societal behaviour is now</a>).

What would it take to create global society?  There would need to be evolutionary pressure towards it.   Our own societies were created by the following evolutionary forces:
<ol>
	<li>Economies of scale and division of labour (specialisation) lead to more value creation within a given group of people.  These would have formed the first micro-societies such as tribes.</li>
	<li>Larger societies would be able to out-compete the smaller ones (through devotion of resources to warfare)</li>
	<li>Larger societies begin to need currencies and laws to hold them together.  Currencies and laws lead to more value creation within a society.  These society types out-compete the ones without those.</li>
	<li>As does top-down control - societies with effective top-down control create much more value than those with poor or no control.</li>
</ol>
<div>You might be able to see how this applies on a global level.  Let's go through the list:</div>
<div>
<ol>
	<li>We already have things like trading blocks, and country-level specialisation.</li>
	<li>This clearly happens, look at Britain, then the US, now China.</li>
	<li>Compared to one hundred years ago, great strides have been made in this area, with the UN, human rights, international standards.</li>
	<li>We have little top-down control so far.</li>
</ol>
<div>So, you can argue that we are moving in the right direction for global-level society.  This sounds like an excellent approach for the future stewardship of the planet.  Global government could clearly help us solve big problems like climate change.  What is missing is evolutionary pressure from competition to cause this to happen - there's only one global society.</div>
<div>In any case, would it necessarily lead to a socialist outcome over a value-generating one?   That would be a decision for that super-society to make.  One problem is, would we want them to?</div>
</div>
<h1>Jobs For the Sake Of It</h1>
Another problem with halting progress so that humans stay useful is that it would just be creating jobs for the sake of it.  Is that a good thing?   Would people be happy doing work that could be trivially automated by more intelligent machines?  Would people be happy knowing that the best they can do is second best to machine intelligences?  I am not sure they would.

Should we loosen the requirement?  How about a version of the future where humans are merely happy?   The global super-society provides us with the resources we need to do what we want, and we just consume them (somehow, we have persuaded the automated, global super-society that it is there to serve humanity).   There's a problem here though is this:

What makes us happy is built into our genes.  And our happiness is our gene's reward for fulfilling their program.  We have been evolved, like all species, to generate value.  That is, <a title="Lifeforms, Resources and Value" href="http://robmoff.at/2012/05/05/lifeforms-energy-and-value/">gather more useful resources than we consume</a>.    If we are just given the resources we need, will we actually be happy?

Personally, I can't see how this would necessarily be any different from being in prison:  resources are still finite, so h

&nbsp;

&nbsp;

&nbsp;]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>200</wp:post_id>
		<wp:post_date><![CDATA[2013-07-01 09:43:13]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2013-07-01 09:43:13]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[]]></wp:post_name>
		<wp:status><![CDATA[draft]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="category" nicename="singularity"><![CDATA[singularity]]></category>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
			<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
	</item>
	<item>
		<title>Are Humans The Horses of the 21st Century?</title>
		<link>http://robmoff.at/2013/06/10/are-humans-the-horses-of-the-21st-century/</link>
		<pubDate>Mon, 10 Jun 2013 12:39:12 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://www.robmoffat.co.uk/?p=207</guid>
		<description></description>
		<content:encoded><![CDATA[When I was 5 years old, I saw a<a href="http://en.wikipedia.org/wiki/Rag-and-bone_man"> rag-and-bone man</a> riding his horse and cart down our road in New Houghton.  It was the first and last time in the UK that I ever saw a horse being used for anything other than a recreational activity.  But at the start of the 20th Century, horses were used for lots of things: ploughing fields, for transport or war.   Basically, any time you needed some, er, horsepower.

Those days are long gone, and the engine has supplanted them.

Lots of people wonder what will happen to humanity in the 21st Century.   Optimistic futurists say we will evolve into <a title="Humanity Plus" href="http://humanityplus.org.uk">humanity+</a>, free of the shackles of our biological lifespan and able to roam the galaxy.  Others see us as relinquished of <a title="Post Work Humans" href="http://www.nytimes.com/2013/02/24/opinion/sunday/douthat-a-world-without-work.html?_r=0">our work responsibilities</a>, to be looked after by machines that attend our every need.

Pessimistic futurists worry about the<a href="http://www.forbes.com/sites/gregsatell/2013/05/04/should-we-fear-the-rise-of-the-robots/"> Rise of the Robots</a>, <a href="http://en.wikipedia.org/wiki/Terminator_(franchise)">Terminator-style armaggeddon</a>, or that the planet will be turned to <a title="Grey Goo" href="http://en.wikipedia.org/wiki/Grey_goo">grey ooze by nanotechnology</a>.

I have a much more mundane alternative:  Humans will slowly be replaced, exactly like horses were.   Instead of petrol engines slowly accelerating in power and convenience to replace the horse, technology will do the same for the human intellect.   Have a look at this video:

<a href="http://www.ted.com/talks/andrew_mcafee_are_droids_taking_our_jobs.html">andrew_mcafee_are_droids_taking_our_jobs.html</a>

&nbsp;

Andrew McAfee makes a strong argument for the notion that society is improved by technology taking over our jobs.  He says that culture is enriched as technology has improved.   I totally agree.  The problem is, humans will be a decreasing part of this culture.  Our culture was enriched by the invention of the steam and petrol engines, but horses ended up playing much less of  a part in it.   Humans will be required less and less to input into the culture, and, the more they get involved, the more they'll be getting in the way.
<h2>Human 2.0?</h2>
One argument against this state of affairs is that we will evolve with our technology.  It's a nice idea: we already have powerful desktop computers, iPads and smart-phones which augment our own abilities.   After Google Glass, maybe we'll have internal implants that improve our cognitive abilities, networking us all together.   Maybe.

Technologies magnify our own abilities, in much the same way as a carriage allows a horse to do a better job of carrying people.    But if something else comes along which can do what we do, but better, it will eventually replace us due to the invisible hand of economic efficiency and the power of competition.   That is:
<blockquote>A business still running using horses/humans whilst their competition has moved on to cheaper, more efficient engines/computers will have higher overheads, be less profitable and eventually go out of business.</blockquote>
<h2>Humans at Rest?</h2>
It would be nice to suppose that our working days might be over, and as a species we can setting down to a life of contented retirement, waited on hand and foot by digital slaves.   For the vast majority of horses, this didn't happen.

The horses weren't simply put to pasture, and left to reproduce and carry on with their previous, wild existences.  Otherwise, there'd be a lot more of them around today.  Whilst some are still kept for pleasure, the working horse population has been shrunk massively.

Just because it happened for horses, would it happen for humans?  Let's say each person in the UK were given a share in the profits of all (now machine-run) businesses in the UK.   Could they be supported indefinitely, to continue living and reproducing without needing to work?  No.  Again, for economic reasons:
<blockquote>Businesses supporting a human population would have higher overheads than ones not supporting a population.  They would therefore be less competitively fit, and therefore eventually go out of business, out-competed by more profitable businesses.</blockquote>
<h2>Humans Free To Help?</h2>
Once humans are freed of the need to perform the daily grind, couldn't they just get on with something else?  This is an economic shift that has happened time and again:  with the invention of the engine, employment moved from being chiefly agricultural to industrial.  With improved automation, employment shifted from the industrial to service and information technology areas.  Won't there be another shift?
<blockquote>I would argue that actually, there <em>will</em> be another shift - Because machines will get cleverer than us before they get more agile than us, we are likely to have human plumbers and nurses and so on for longer than we will have human fund managers and human programmers.  Once machines are smarter than us, and more agile than us, there aren't going to be any new niches we can retreat to.</blockquote>
Just as you don't see many horses manning a mobile 'phone shop, or helping out in a call centre, humans won't be much use in the society of tomorrow.  Maybe the few that are left could "do their own thing" regarded by the future citizens of society as we look at zoo animals today.

Maybe they'll just jump on our backs and ride us round for fun every now and again.
<h2>The Parent Trap</h2>
Our fate is in a way the same as that of every parent:  to grow older and see your children replace you.  The difference is that this time, it will be our<em> in silico</em> offspring that replace us, rather than our biological ones.  I don't want to be replaced at all, but inevitably, one day I will.

Is this the fate we choose, though?  I would be hugely relieved if someone could tell me where my argument is wrong.]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>207</wp:post_id>
		<wp:post_date><![CDATA[2013-06-10 12:39:12]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2013-06-10 12:39:12]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[are-humans-the-horses-of-the-21st-century]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="category" nicename="singularity"><![CDATA[singularity]]></category>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
			<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_thumbnail_id]]></wp:meta_key>
			<wp:meta_value><![CDATA[208]]></wp:meta_value>
		</wp:postmeta>
		<wp:comment>
			<wp:comment_id>40</wp:comment_id>
			<wp:comment_author><![CDATA[bobm]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[robmoffat@mac.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[109.158.190.167]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2013-06-30 18:21:25]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2013-06-30 18:21:25]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Horses are tools, but people aren't?  I'm not really sure how you can argue that in either direction...  I think adding the concept of "tools" in there is just complicating the issue.   I prefer to look at it from a value perspective: horses, people, cars, tools all generate value for society.  

However, these days, horses not so much.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[]]></wp:comment_type>
			<wp:comment_parent>39</wp:comment_parent>
			<wp:comment_user_id>1</wp:comment_user_id>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
				<wp:meta_value><![CDATA[a:4:{s:4:"time";s:15:"1372616485.9004";s:7:"message";s:28:"Akismet cleared this comment";s:5:"event";s:9:"check-ham";s:4:"user";s:4:"bobm";}]]></wp:meta_value>
			</wp:commentmeta>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
				<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
		</wp:comment>
		<wp:comment>
			<wp:comment_id>39</wp:comment_id>
			<wp:comment_author><![CDATA[ibrahim diallo]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[ibrahim@idiallo.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://idiallo.com</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[184.255.188.239]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2013-06-29 02:04:02]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2013-06-29 02:04:02]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[It makes sense but we will be replaced by something better and more efficient. However the horse metaphor is not the best. The horse was used as a tool, just like the car. It was used by humans as a mean to satisfy humans. Now the horse is gone and the car is here. 
The metaphor falls short because we are not the tool, we are using it.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
				<wp:meta_value><![CDATA[a:4:{s:4:"time";s:15:"1372615778.7441";s:7:"message";s:43:"bobm changed the comment status to approved";s:5:"event";s:15:"status-approved";s:4:"user";s:4:"bobm";}]]></wp:meta_value>
			</wp:commentmeta>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
				<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
				<wp:meta_value><![CDATA[a:4:{s:4:"time";s:15:"1372471442.6997";s:7:"message";s:28:"Akismet cleared this comment";s:5:"event";s:9:"check-ham";s:4:"user";s:0:"";}]]></wp:meta_value>
			</wp:commentmeta>
		</wp:comment>
		<wp:comment>
			<wp:comment_id>38</wp:comment_id>
			<wp:comment_author><![CDATA[Some Guy]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[craigslistuser@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[76.21.46.243]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2013-06-28 23:57:57]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2013-06-28 23:57:57]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[For what it's worth, Ted Kaczynski gave a lot of thought to this problem. Take a look at paragraph 174 of the Unabomber Manifesto:

174. On the other hand it is possible that human control over the machines may be retained. In that case the average man may have control over certain private machines of his own, such as his car of his personal computer, but control over large systems of machines will be in the hands of a tiny elite -- just as it is today, but with two difference. Due to improved techniques the elite will have greater control over the masses; and because human work will no longer be necessary the masses will be superfluous, a useless burden on the system. If the elite is ruthless the may simply decide to exterminate the mass of humanity. If they are humane they may use propaganda or other psychological or biological techniques to reduce the birth rate until the mass of humanity becomes extinct, leaving the world to the elite. Or, if the elite consist of soft-hearted liberals, they may decide to play the role of good shepherds to the rest of the human race. They will see to it that everyone's physical needs are satisfied, that all children are raised under psychologically hygienic conditions, that everyone has a wholesome hobby to keep him busy, and that anyone who may become dissatisfied undergoes "treatment" to cure his "problem." Of course, life will be so purposeless that people will have to be biologically or psychologically engineered either to remove their need for the power process or to make them "sublimate" their drive for power into some harmless hobby. These engineered human beings may be happy in such a society, but they most certainly will not be free. They will have been reduced to the status of domestic animals.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
				<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
				<wp:meta_value><![CDATA[a:4:{s:4:"time";s:14:"1372463877.224";s:7:"message";s:28:"Akismet cleared this comment";s:5:"event";s:9:"check-ham";s:4:"user";s:0:"";}]]></wp:meta_value>
			</wp:commentmeta>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
				<wp:meta_value><![CDATA[a:4:{s:4:"time";s:15:"1372615778.7539";s:7:"message";s:43:"bobm changed the comment status to approved";s:5:"event";s:15:"status-approved";s:4:"user";s:4:"bobm";}]]></wp:meta_value>
			</wp:commentmeta>
		</wp:comment>
		<wp:comment>
			<wp:comment_id>41</wp:comment_id>
			<wp:comment_author><![CDATA[bobm]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[robmoffat@mac.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[109.158.190.167]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2013-06-30 18:27:41]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2013-06-30 18:27:41]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[I guess like me, old Ted sees more likelihood in the negative scenarios than the positive ones.   

I would love one of the more positive outcomes to be the case, but I am leaning towards the negative ones because of the historical precedent I describe above.

What do you think?]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[]]></wp:comment_type>
			<wp:comment_parent>38</wp:comment_parent>
			<wp:comment_user_id>1</wp:comment_user_id>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
				<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
				<wp:meta_value><![CDATA[a:4:{s:4:"time";s:14:"1372616861.544";s:7:"message";s:28:"Akismet cleared this comment";s:5:"event";s:9:"check-ham";s:4:"user";s:4:"bobm";}]]></wp:meta_value>
			</wp:commentmeta>
		</wp:comment>
	</item>
	<item>
		<title>Breaking Inversion Of Control</title>
		<link>http://robmoff.at/2015/10/09/breaking-inversion-of-control/</link>
		<pubDate>Fri, 09 Oct 2015 11:09:11 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://robmoff.at/2015/10/09/breaking-inversion-of-control/</guid>
		<description></description>
		<content:encoded><![CDATA[


Inversion of control is much like pure functional programming, but watered down.

<table>
<tr>
<td>

</td>
<td>
Pure Functions
</td>
<td>
IoC
</td>
</tr>
<tr>
<td>
You don’t go off and resolve your own dependencies
</td>
<td>
Y
</td>
<td>
Y
</td>
</tr>
<tr>
<td>
Don’t change the state of your context (side effects)
</td>
<td>
Y
</td>
<td>
N
</td>
</tr>
<tr>
<td>
Deterministic (rely only on other pure functions)
</td>
<td>
Y
</td>
<td>
N
</td>
</tr>
</table>

Actually, I think that’s it.  The difference is that purity means you don’t change the context.

This means with pure functions, you can be <i>lazy,</i> and only evaluate when the result is needed.  This is an optimisation.  Also, knowing you haven’t changed the context is valuable, as you can cache the result.




]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>216</wp:post_id>
		<wp:post_date><![CDATA[2015-10-09 11:09:11]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2015-10-09 11:09:11]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[breaking-inversion-of-control]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="post_tag" nicename="antipatterns"><![CDATA[antipatterns]]></category>
		<category domain="post_tag" nicename="blog"><![CDATA[blog]]></category>
		<category domain="category" nicename="software"><![CDATA[software]]></category>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
			<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
	</item>
	<item>
		<title>Thoughts on Information</title>
		<link>http://robmoff.at/2015/10/09/thoughts-on-information/</link>
		<pubDate>Fri, 09 Oct 2015 11:09:14 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://robmoff.at/2015/10/09/thoughts-on-information/</guid>
		<description></description>
		<content:encoded><![CDATA[


<i><b>Content Aggregators like Facebook, Instagram, Reddit, HackerNews, Medium, Google have the power these days, because that’s where the audience is.</b></i>
<i><b></b></i>
<a href="https://medium.com/matter/the-web-we-have-to-save-2eb1fe15a426">https://medium.com/matter/the-web-we-have-to-save-2eb1fe15a426</a>
<a href="http://www.theawl.com/2015/07/in-no-charts">http://www.theawl.com/2015/07/in-no-charts</a>

TL;DR:  Content creators are therefore in a oligopolistic position:  no-one visits websites anymore, they consume on Facebook.  This means that the aggregators have all the power in the relationship, and can set their own arbitrary rules.

<b>Information likes to be free</b>
<b></b>
(see<b> </b>also <a href="https://en.wikipedia.org/wiki/Information_wants_to_be_free">https://en.wikipedia.org/wiki/Information_wants_to_be_free</a>)
<b></b>
Content creators have no control over the duplication of their information.  And they work in a highly competitive landscape.  Even creators that could set up paywalls therefore suffer piracy (films, music etc) or are substitutable (online magazines).

Conversely, <i>virality</i> occurs because the same information is relevant to a large audience.  We regard vitality as a measure of how many people want to see the information, coupled with the desire to share it.

Content Aggregators therefore make it easy to create and propagate viral information.

<b>Compare to Kite9</b> 

Kite9 is also information-based, but the diagrams it produces are relevant only to the people that work on them.  Therefore, Kite9 is not going to suffer from the piracy problem (unless the algorithm is stolen):  people aren’t going to take their paid-for Kite9 diagrams and give them away.  No one else would be interested.

This is <i>inverse-virality</i>:  Information likes to be free, yes.  But if it is only interesting to a small group, you can effectively control the audience and create controls around it.

This is also the <i>value of the content aggregator</i>:  They provide a tailored, personal feed of information about what your friends are doing, and things that may be of interest to you.  This is inversely-viral too.  And this is why the aggregators have power:  There is no value in you duplicating your feed and publishing it for free on the internet.  The information is free, but <i>valueless to anyone but you.</i>
<i></i>
<i>Kickstarter Campaigns</i> often work like this:  you add paid-for incentives that personalise the experience in some way.  Even if you are receiving a pure-information experience (say a podcast), having your name in it improves that experience and makes it worth paying for.  
<i></i>

<b>Value Of Information</b>


While information likes to be free, it does have a value nonetheless.  This is why people watch films and pirated films: both have value, one is free.

Content Aggregators try to asses, for each person, the value of the content to that person, to some extent.   On say Facebook, this is done by:

<ul>
<li>Looking at the posts of your friends</li>
<li>Suggesting friends based on other friends</li>
<li>Looking at your “likes&quot;</li>
<li>Looking at what you read and commented on.</li>
<li>Looking at what you’ve already seen (and probably excluding it)</li>
</ul>
 
Hacker News, on the other hand works this out by:
<ul>
<li>Number of comments and up-votes</li>
<li>Freshness of the article</li>
</ul>

Twitter does this by:
<ul>
<li>Looking at your “following list&quot;</li>
<li>Looking at buzzwords and tags to see how prevalent they are (compared to usual)</li>
</ul>

All of these algorithms essentially try to establish the <i>value</i> of the information to <i>you.  </i>Hacker News asks you to (further) filter based on what you have seen already.  

<b>Battle Hardening</b>
<b></b>
Content Aggregators also need to fight against sabotage of their algorithms.  Google used to aggregate by:

<ul>
<li>Web Pages containing your search term</li>
<li>How many links to that web page there was on the rest of the internet</li>
</ul>

They had to drop the latter measure, because it could be <i>gamed</i> by people with an interest in pushing their information. 

<b>Advertising</b>

This brings us onto the fact that the consumption of information has value to the reader and the writer.   In our (capitalist) world, lots of people are pushing to us information to sell us things, in the form of advertising.   Advertising is information which, when consumed delivers value to the content creator.  Ideally, it should also deliver value to the consumer:  advertising uses humour or captivating imagery for this purpose, or acts as infotainment, or tries to pass itself off as editorial, to give you the impression that you are being <i>informed. </i>
<i></i>
When we accidentally consume an advertisement, we often feel duped or used.  But the same thing isn’t true of a meme like a viral video.  We kind of assume that the video creator isn’t benefiting from us watching the video, so that feels better.  

The feeling of “being duped” is a defence mechanism for us:  we have learnt something from the information, but now we have to correct, and revise that knowledge in the light of the fact that someone has fed us that knowledge <i>for their own gain.</i> 

Facebook is constantly making advertising look more like regular content.  Every time they do this, the click-through rate improves, because people are duped without realising.   Also every time they do this, people’s <i>anti-duping filters</i> need to improve, so that they realise that <i>hey, this is advertising again, watch out!</i>
<i></i>
<b>Harmful Content</b>
<b></b>
Our computers have ways to combat harmful viruses, in the form of software.   Similarly, Meme-viruses have to be benign to some extent to be propagated.  Certain images which <i>could</i> be put on Facebook are deemed <i>harmful</i> or <i>sick </i>(torture etc).  These are barred by the network itself:  people actually have the job of checking these images and removing them.  But, this is harmful to those people too.

So we have a matrix here:

<table>
<tr>
<td>

</td>
<td>
No Financial Benefit To Creator 
</td>
<td>
Financial Benefit To Creator
</td>
</tr>
<tr>
<td>
Cost to Consumer
</td>
<td>
“Sick” Content
</td>
<td>
Regular Advertising
Advertising via duping.  
Infomercials
</td>
</tr>
<tr>
<td>
Value and Cost to Consumer
</td>
<td>

</td>
<td>

Paywalled articles
Newspapers
Magazines 

Books etc.
</td>
</tr>
<tr>
<td>
Just Value to Consumer
</td>
<td>

Memes

News Articles
Sharable Content
Status Updates
</td>
<td>
&lt;impossible&gt;
</td>
</tr>
</table>

In reality, items of content don’t fit neatly into one box.  A BuzzFeed or Huffington Post article <i>to some extent</i> advertises that institution.  Memes sometimes have branding.  News articles may deliberately or accidentally give the oxygen of publicity to one institution or other.

Content aggregators actually walk quite a tightrope, because they have to weigh up being beneficial to both the content creators (who will pay for advertising) and the consumers.  So actually, it’s probably not quite the slam dunk that the two linked articles suggest.  Yes, they can create crazy rules that annoy consumers and unfairly penalise individual creators.  But, on the other hand, this is oligopoly:  the aggregators have competition, and they need to deliver comparable value to each other, and the web in general.

<b>Further Breakdown</b>
<b></b>
It seems to me that the “Value to the Consumer” square needs to be broken down much further.  HackerNews delivers a very different kind of proposition to Facebook, for example.  A scientific journal, quite another.  

<b>Biological Organisms</b>

In the human body, we have an immune system that works in two ways:

<ul>
<li>Defence:   Basically, anti-bodies look for things that are not part of the body and attack them.</li>
<li>Immunity:  We detect features of the viruses, and learn to combat them.</li>
</ul>

We have similar systems on computers in the form of virus checkers, spam detectors.   

In this section, I want to relate the kinds of information systems within our bodies, to the kinds on the internet. 

Obviously, we want to prevent ourselves from being influenced by harmful information.  <i>Society</i> has some norms about what is considered harmful, and sites like Facebook are <i>obliged</i> to police content according to these principles: nudity, happy-slapping, under-eating, threats and worse are removed from Facebook.
 
They are first reported, and then checked and removed, and placed on a blacklist of things that can’t be posted again.  This has obvious parallels to our immune system.

<b>Curation</b>

One thing content aggregators do, (from Facebook, to Twitter, to Google) is curation.  There are some subtle things going on with this:   
<ul>
<li>Facebook curates based on likes, and a complex algorithm to determine what goes on your front page. </li>
<li>Google also uses keywords.  But, uses likes and other metrics to determine ranking. (Which is essentially curation)</li>
<li>Twitter allows you to view stuff in temporal order.  It doesn’t curate in the traditional sense, but relies on other people to re-tweet some interesting stuff.  Also, you can view in temporal order based on a search-term.  Other people watch for the search term.  The 140 character rule is a leveller.</li>
<li>Hacker news has it’s ranking algorithm, based on up-votes, comments, and time-decay.  </li>
</ul>

<b>Ensuring Balance</b>

One thing you get in the regular, edited news is an effort towards balance.  However, on FB, Google, etc.  there is no effort towards this.  Sites such as HackerNews will essentially tend to publish stuff which is amenable to their readership.  There is a strong bias towards the news that will sell.  

This obviously happens in newspapers too.  And, we know it happens on Google.  

The problem is that this is <i>obviously bad</i> if I am consuming news.  The next generation of algorithms needs to fix the balance problem.  

<b>Wish List</b>

I have a set of interests.  But, I should not just be spoon-fed those interests 
Also, I click on link-bait and cat videos.  I shouldn’t just get these.  
I should be <i>somehow</i> given a broadsheet style view of <i>everything that’s going on</i> on the internet.
Twitter is somewhat like this, but perhaps too broad.
Facebook and Hacker News are the opposite of this.
Sometimes I want to read short articles.  Sometimes, long form.
Sometimes, fiction books.  Sometimes, news headlines.
Can I be given a menu of choices?

A self-created <i>magazine, of sorts.</i>




]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>217</wp:post_id>
		<wp:post_date><![CDATA[2015-10-09 11:09:14]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2015-10-09 11:09:14]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[thoughts-on-information]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="post_tag" nicename="blog"><![CDATA[blog]]></category>
		<category domain="category" nicename="information-theory"><![CDATA[information theory]]></category>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
			<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
	</item>
	<item>
		<title>Stored Procedures Are Evil</title>
		<link>http://robmoff.at/2015/10/09/stored-procedures-are-evil/</link>
		<pubDate>Fri, 09 Oct 2015 11:09:16 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://robmoff.at/2015/10/09/stored-procedures-are-evil/</guid>
		<description></description>
		<content:encoded><![CDATA[


For multiple reasons, under certain circumstances.

1.  If you restrict yourself to plain SQL, you can move between databases.  This is really handy if you want to be able to create in-memory databases for testing, vs. production databases, which are something else.

2.  Your logic is no longer in a single place.  This makes it harder to reason about.   Of course, if you are somehow implementing the entire application as stored procedures, then maybe this isn’t a problem. 

3.  SELECT is pure functional programming.  That’s really great.  But SP’s may have side-effects.  That makes them harder to reason about.

4.  They’re hard to test, although it’s not impossible.  

5.  Chances are, you can generate your DB using domain objects if you have good domain object meta-data (see hibernate, GORM etc).  With stored procs, this is not going to happen.

6.  The language you are using to define stored procedures was probably invented in the 1980’s.  There’ve been lots of improvements in language design since then.

]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>218</wp:post_id>
		<wp:post_date><![CDATA[2015-10-09 11:09:16]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2015-10-09 11:09:16]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[stored-procedures-are-evil]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="post_tag" nicename="blog"><![CDATA[blog]]></category>
		<category domain="category" nicename="software"><![CDATA[software]]></category>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
			<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
	</item>
	<item>
		<title>Evolutionary Complexity</title>
		<link>http://robmoff.at/2015/10/09/evolutionary-complexity/</link>
		<pubDate>Fri, 09 Oct 2015 11:09:19 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://robmoff.at/2015/10/09/evolutionary-complexity/</guid>
		<description></description>
		<content:encoded><![CDATA[


<b>In the building industry</b>
<b></b>
<ul>
<li>Materials evolve and improve, allowing us to build better buildings.</li>
<li>Human needs stay constant.  </li>
</ul>

<b>In the software industry</b>

<ul>
<li>Hardware evolves at an exponential rate</li>
<li>Programming languages change somewhat slowly</li>
<li>Implementations of PLs change rapidly</li>
<li>Libraries for programming languages change rapidly. <i>(Open Source software is a model of competitive evolution, with successful software attracting users and development talent in order to improve itself faster than unsuccessful competitors. )</i></li>
<li>The content on the internet changes rapidly</li>
<li>Development practices try to keep up</li>
<li>Requirements evolve at the pace of business (i.e. fairly rapidly)</li>
</ul>

Could evolutionary complexity be the main source of difficulty for software engineering?  

<b>Upshot</b>

Stable elements that have proved themselves will evolve faster.  This is because elements that create value will receive more evolution.

Evolution is random mutation in nature. It’s little better in our eco-system:  people can be good or bad programmers, all have different ideas about what they want the software to do, and those ideas will live or die in the real world when tested against real situations.

The human brain allows us to model and plan ahead, but at the end of the day, it is limited as a tool and our ideas still have to be tested in the real world.  Can they survive in their niche?

<b>It’s Not Engineering, Is It?</b>

We’re not building things to last.  We can’t.  The whole foundation upon which we construct our software is not fixed like the Earth, it is evolving rapidly.  

We can either choose to <i>minimize dependencies that might change</i>, which means our software is reliable, but fixed in time and unable to evolve.  Generally, in-house applications will choose the this route. 

-or-

We can try to <i>keep on top of change</i> and keep building our software against new libraries and infrastructure, in the knowledge that this will be fragile and keep us busy.  
Wordpress, and operating systems, choose this route. 

<b>Is there a dichotomy here or not?</b>
<b></b>



]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>219</wp:post_id>
		<wp:post_date><![CDATA[2015-10-09 11:09:19]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2015-10-09 11:09:19]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[evolutionary-complexity]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="post_tag" nicename="antipatterns"><![CDATA[antipatterns]]></category>
		<category domain="post_tag" nicename="blog"><![CDATA[blog]]></category>
		<category domain="category" nicename="information-theory"><![CDATA[information theory]]></category>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
			<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
	</item>
	<item>
		<title>Humane Manifesto</title>
		<link>http://robmoff.at/2015/10/09/humane-manifesto/</link>
		<pubDate>Fri, 09 Oct 2015 11:09:22 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://robmoff.at/2015/10/09/humane-manifesto/</guid>
		<description></description>
		<content:encoded><![CDATA[


<b>We should understand the practices and processes being used in the best software projects, and then develop tools that enable those practices and processes for everyone else, without them really having to try.</b>

Activities need to reward you at the point when you complete them, not way down the road by saving time.

It shouldn’t be about learning new practices, and adopting new ways of working.  Programming is already full enough with gotchas and edge-cases to learn about.  

It should be obvious what to do next.  It might not always be coding.  (<i>Visibility)</i>

Most developers aren’t rock-stars.  But, they should be able to get things done too.  Favour simple, obvious tools rather than the most productive ones.

We should be using technology to make our lives easier.  In the same way we set an alarm clock in the morning, we should be able to use software to help us do the right thing.

<b>How can we automate the right development process?</b>









]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>220</wp:post_id>
		<wp:post_date><![CDATA[2015-10-09 11:09:22]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2015-10-09 11:09:22]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[humane-manifesto]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="post_tag" nicename="blog"><![CDATA[blog]]></category>
		<category domain="category" nicename="management"><![CDATA[management]]></category>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
			<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
	</item>
	<item>
		<title>“Ta-Darchitecture&quot;</title>
		<link>http://robmoff.at/2015/10/09/ta-darchitecture/</link>
		<pubDate>Fri, 09 Oct 2015 11:09:25 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://robmoff.at/2015/10/09/ta-darchitecture/</guid>
		<description></description>
		<content:encoded><![CDATA[


<b>Name:</b>  &quot;Ta-Da” Architecture.  Named for the sound made to accompany a magician when pulling a rabbit out of the hat.

<b>Problem:</b>  A grand unveiling of the design, put together by some (often well-meaning) cabal.
 
<i>“I know you’ve all been waiting for this for a while.  And yes, I know lot’s of plans have been on hold while we get this thing nailed down, but finally, I’d like to present to you all the architecture for our new software system.  It’s amazing, and it will replace everything we’ve got at the moment which is all now legacy.  Let me take you through this powerpoint presentation showing you what we’re going to build.&quot;</i>

This is how it starts.  Junior developers lean forward in their chairs. <i>Hey, we’re actually going to be shown… the future!</i> But the seasoned hacks sigh and roll their eyes.  <i> </i> They’ve seen this before.  Another well-meaning, but hastily put together design which fails to correspond to any view of reality other than the author’s. 

Maybe it’s been done by a consultancy.  Maybe it’s been put together by some management “strategy” group.  The Big Ta Da! Architecture is characterised by strict secrecy up to the point of revelation.  But, this strict secrecy means that it has not been exposed to the kind of rigorous cross-examination or exposure to actual business requirements that might lead to a cogent, well-thought through design.

Often, the Ta Da Architecture is warmly received by budget holders:  There is something special in the banking world about having a “vision”.  In fact, one of the Ta-Da Architectures I’ve witnessed was called “Vision”.  It lasted for nearly two years and sucked in vast amounts of money.  For the executive proposing it, it was warmly received and got lavish funding.  Initially.  The problem was, after a year or so the realisation set in that actually, the architectural vision had prevented important business critical functionality from being delivered.  It was unceremoniously canned and the instigator moved on to pastures new.

Ta Da Architectures often disenfranchise staff who might have been in a position to contribute meaningfully.  These staff are able to see the obvious mistakes and oversights present in the system, but usually powerless to do anything about it:  once announced, the Ta Da Architecture is as good as approved, there’s no point complaining now.

<b>Context: </b>
<ul>
<li>You are working in a growing organisation.  </li>
<li>Stakeholders worry about the heterogenicity of the environment, or “legacy” systems.</li>
<li>There’s plenty of budget available to support pie-in-the-sky thinking.  </li>
<li>Budgets need to be justified to some extent with strategic direction.</li>
</ul>

<b>Building banking software is hard: </b>
<ul>
<li>There is complicated maths involved.</li>
<li>It’s difficult to tell the difference between things that work and things that don’t.</li>
<li>There are lots of exceptions to contend with.</li>
<li>The data sets get large.</li>
<li>There are lots of legacy systems.</li>
</ul>

<b>Forces:</b>
<ul>
<li>The need to &quot;come up with something” to appease stakeholders/budget holders.</li>
<li>The need to look good in meetings:  if you have an architecture that keeps the stakeholders happy, then in the short term you can silence your critics.</li>
<li>Strategic plans are needed soon.</li>
<li>Architecture is <i>fun</i>.  People like starting with a clean slate.</li>
</ul>

<b>Supposed Solution:</b>
<ul>
<li>It will take too long to build up a set of use-cases, or a detailed set of requirements, so don’t bother with those.</li>
<li>Equally, involving everyone in a decision making process will be too time consuming.  </li>
<li>Based mainly on gut feel or previous experience, sketch out new architecture and create a powerpoint presentation.</li>
<li>Present the architecture to the budget holders to rapturous applause and approval.</li>
<li>Present the architecture to the project teams as a <i>fait accompli</i> to begrudging acceptance.<i>  Ta Da!</i></li>
</ul>

<b>Resulting Context:</b>
<ul>
<li>Many of the constraints proposed are unlikely to fit the actual requirements of the projects being undertaken.</li>
<li>Rather than solving any problems, the TaDarchitecture is actually a <i>whole new set of requirements</i> that projects now need to meet.</li>
<li>Often, these requirements will be nonsensical under detailed analysis and thought, because they were only ever intended to pass muster with budget holders.</li>
<li>Lots of people feel disillusioned that their opinions weren’t considered.</li>
</ul>
<b></b>
<b>Warning Signs</b>

<ul>
<li>Designs that promise functionality “for free”.</li>
<li>Designs which aren’t backed by requirements.</li>
<li>Whole-cloth solutions, rather than individual ideas which can be implemented on their own.</li>
</ul>


<b>Related Anti-Patterns:</b>  
     Waterfall
     BigDesignUpFront
     BusinessAren’tBudgetHolders
     GoldOwnerIsNotGoalDonor

<b>Compare With:</b>
<ul>
<li>YAGNI</li>
<li>3 Strikes Then Refactor</li>
<li>Use Cases</li>
<li>Collaborative Design</li>
</ul>





]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>221</wp:post_id>
		<wp:post_date><![CDATA[2015-10-09 11:09:25]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2015-10-09 11:09:25]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[ta-darchitecture]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="post_tag" nicename="antipatterns"><![CDATA[antipatterns]]></category>
		<category domain="post_tag" nicename="blog"><![CDATA[blog]]></category>
		<category domain="category" nicename="management"><![CDATA[management]]></category>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
			<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
	</item>
	<item>
		<title>Why Jira Fails</title>
		<link>http://robmoff.at/2015/10/09/why-jira-fails/</link>
		<pubDate>Fri, 09 Oct 2015 11:09:28 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://robmoff.at/2015/10/09/why-jira-fails/</guid>
		<description></description>
		<content:encoded><![CDATA[


Bug &amp; feature tracking should be really simple, but it ends up not being.   Here are two problems:

<b>The Extra Field</b>

At some stage, someone requests that they can sort by some new field.  Like, “Service Name” or something banal.  This gets used by some people on the project, but not everyone, and not consistently.  The integrity of the database is now compromised.  You can’t rely on “Service Name”.

Quick Fix:  Tagging

<b>The Lifecycle Bloat</b>

Someone says, we need another stage in the lifecycle of a bug, called &quot;Pre-UAT Testing&quot;.   This is added.  Now, we all have to work through a more complicated lifecycle.  This gets used by some people on the project, but not everyone, and not consistently. 

The integrity of the database is now compromised.  You can’t rely on “Pre-UAT Testing” always being a thing.

<b>What Went Wrong?</b>

Not everyone has the same mental model of the process, or the shape of the system.  They then try to change the system to map onto their mental process.  In the process though they introduce complexity, and confusion.  Now the system fails to map onto other people’s mental processes. 

There is a good argument for using the Lowest Common Denominator.  This maps onto no-one’s understanding of the process.  In fact, it might change the process to be something simpler as people adapt.  

Different software processes have different requirements, but Jira tries to meet all of these requirements, and bloats in complexity because of this.

The BitBucket Issue Tracker was better than Jira, because of everything it left out, not because of what features it had.

<b>Summary</b>

<ul>
<li>If there are n people in the system, then we have n+1 models of the system, where the extra one is Jira.</li>
<li>Ideally, we need to harmonise these n+1 models into the single model of Jira. </li>
<li>But, for some people, their model will not fit into Jira.</li>
<li>If we change Jira, then it’s likely to be more complicated, and people are less likely to understand the model in Jira.</li>
<li>Some models in n don’t make any sense at all, when they’re thought through.  Sometimes, they end up being the model used in Jira.</li>
</ul>

<b>How To Solve This Problem</b>

<ul>
<li>The development process should define the tracker.  The tracker should support the development process.  </li>
<li>Both the tracker and the development process need to be so stupidly straight forward that everyone can understand the model. </li>
<li>Both the tracker and the development process need to be sufficient to build software properly.</li>
<li>If you want people to use your development process, bake it into software so they have to accept your model.</li>
</ul>






]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>222</wp:post_id>
		<wp:post_date><![CDATA[2015-10-09 11:09:28]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2015-10-09 11:09:28]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[why-jira-fails]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="post_tag" nicename="antipatterns"><![CDATA[antipatterns]]></category>
		<category domain="post_tag" nicename="blog"><![CDATA[blog]]></category>
		<category domain="category" nicename="software"><![CDATA[software]]></category>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
			<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
	</item>
	<item>
		<title>Ramp Up To The Point Of “Impossible&quot;</title>
		<link>http://robmoff.at/2015/10/09/ramp-up-to-the-point-of-impossible/</link>
		<pubDate>Fri, 09 Oct 2015 11:09:30 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://robmoff.at/2015/10/09/ramp-up-to-the-point-of-impossible/</guid>
		<description></description>
		<content:encoded><![CDATA[


<i>A corollary to “Work expands to fill the time available”. </i>
<i></i>
<b>Note:</b> <font face="Courier New"> This entry is not meant to be representative of a single institution.  It’s the result of broad experience and discussions with a number of colleagues working in a number of different Tier One Investment Banks</font>.

The risk department is a heady mix of several competing constraints, which, when taken together, become toxic:

<ol>
<li><b>We don’t want to break anything.  </b>We have to keep the “show on the road” at all times, produce our numbers every day, and not upset the business by producing a set of risk numbers that is significantly worse than it was the day before.</li>
<li><b>We have a growing regulatory burden.  </b>Which means that all the time we are trying to introduce new reports, new metrics and more granularity about what we are doing.  One of the upshots of this is that there is a lot of <i>money</i> for risk.</li>
<li><b>The landscape is too complex.  </b>No one really has a complete understanding of all of the systems in play.  Additionally, systems don’t have sets of automated acceptance tests, so it’s impossible to say for sure what the systems do, or what they are supposed to do.</li>
</ol>

So, why do these elements, taken together, conspire to create a problem?

<b>How It Once Was</b>

You need to start with the understanding that, ten years ago, risk departments were, relatively speaking, <i>poorly funded.</i>  And were not the centre of scrutiny within banks that they now are.  They would be composed of a small set of IT staff who were constantly trading off the complexity of a solution against timeliness against benefit.  

The systems that were produced were somewhat <i>ad hoc,</i> changes were made frequently (perhaps daily) and things got broken.  But the teams responsible were right there, on the ground, with a full understanding and could fix them at the drop of a hat.

The business acted as the testing department, and, as changes were made, wild swings in the risk numbers would warrant urgent ‘phone calls to get it fixed, at any time of the day or night.  

Was this an ideal situation?  No.  This was in the days before continuous integration and automated testing were really the big noise they are now.  But the <i>tight feedback loop</i> made up for this lack to some extent.

<b>What Changed</b>

Then, the Basel regulations happened.  And then the credit crunch.  And suddenly, what had previously been an internal function of the banks now became both really externally important and also a hot news topic at the same time.  

It was time to lose the “backroom boffins” image and modernise Risk departments.

Budgets increased, and staff numbers ramped up accordingly.  Entire off-shore teams appeared to help support the existing applications.   And inevitably, the shortcomings of those existing applications became apparent.

As staff numbers went up, three things happened.    The first was, that the people who had been <i>doing</i> in the first place moved on to start <i>teaching</i> and <i>managing</i> new doers.  Some of the guys didn’t like this, and  left to go to other banks.  But, the story was the same there too, because the regulations had changed for everyone.  Coupled with the rise in new staff, this meant that <i>on average</i> the amount of experience in these systems had decreased, per capita.  

This led onto the second thing happening.  Less experienced staff (and more staff generally) meant that there were more problematic changes.  More things got broken than before.   The ad-hoc feedback loops and systems were no longer good enough to ensure the stability of the systems, so the level of <i>control</i> had to go up:  banks instigated complex release management procedures, access control regimes and sign-offs to prevent accidental mistakes.   They actually had to do this anyway, because of the tighter auditing and regulatory regimes around them.  But this meant that the feedback loops lengthened considerably between someone wanting a change, and the making of that change.  

The third thing that happened following the increased budgets is that the risk staff realised:  now is the chance we have to finally <i>build the systems we always wanted to build.  </i>So they started to build these systems.  But, it wouldn’t be that easy.

<b>Building New Systems</b>

For these staff, experienced in the old ways of keeping production systems running, the obvious thing to do would be to build <i>new</i> systems.   By doing this, you don’t break what you already have:  and that’s one of the major lessons they had learnt being in the risk department already.   Yes, make fixes, change stuff, but try your best not to break the application and get woken up at 4AM to fix it.

Lots of the old, (now legacy) systems were based around databases and stored procedures.  Possibly calling off to some C, C++ or sometimes, Java libraries.   The new world would be Coherence, NoSQL and (latterly) Hadoop (insert buzzwords here).

Getting funding for new projects based on exciting architectures was <i>easy:</i> the budgets were already available to them because of the increased regulatory attention.  What was going to be much harder would be specifying these systems.  Partly this would be because of the lower level of knowledge-per-capita, and partly because so much of the logic and intent of the original systems has been lost over time and wasn’t properly documented in the first place.

<b>In A Hole</b>

So the hole looks like this:  legacy systems are very hard to maintain, and contain hidden, intrinsic knowledge.  New systems are hard to specify, because you either have to avoid stepping on the toes of the legacy systems, or you have to outright replace them, but then you are back trying to understand what the legacy system does.

All the while, you have a huge IT department, trying to implement useful change, wanting to deliver software and wanting to further their careers and improve their CVs. The upshot of this is that lots of “window dressing” projects end up being created:  These are characterized by having lofty ambitions and are long on strategic intent.  This makes them easy to slip by the budget holders, as you sell them on the bright future, but hard to implement in practice.  If not impossible.  

Imagine this going on for several years, so that all the easy, &quot;low-hanging fruit” software has been written. Probably quite badly.  You end up with software projects in development for years, without delivering anything.  The wool being pulled over the eyes of management:  releases that occur but deliver <i>nothing</i> of value (apart from ensuring someone’s bonus).  Testing cycles that go on <i>forever.</i>
<i></i>
<b>Work expands to fill the time available</b>
<i></i>
And, sometimes, work expands to fill the money available.  The money available may not have any relationship to either the <i>perceived value</i> that the project will bring, or even the <i>delivered value</i> of the project.  In the latter case, sometimes not delivering the project will be of greater value than delivering it.

<b>Diagnosis</b>

I <i>want</i> to conclude that what’s needed is more emphasis on automated acceptance testing.  If we had this across the business, we would be able to see:

<ul>
<li>What the software is supposed to do (the test cases give examples of use)</li>
<li>Whether or not it actually does this (the results of running the tests)</li>
</ul>

I <i>would also like to</i> conclude that our problems are partly due to the <i>invisible</i> nature of the software we’ve created:

<ul>
<li>No one is able to walk up to a running risk system and say, for definite, by looking at it, what inputs it needs and from where, what systems it reports into, and where, and how often.  </li>
<li>No one is able to reason about what would happen if we <i>changed</i> part of the system.</li>
<li>Testing burden goes way up:  We don’t have explicit definitions of the interfaces between risk components, It is impossible to draw the boundaries around a testing activity and say for definite, &quot;if we change this component, all others will be unaffected.&quot;</li>
</ul>
 
But, I am not going to conclude either of those things.  Because I think, even if these problems were solved, we would still, somehow, generate the extra complexity to screw ourselves again.  For example, Java got rid of a lot of the pain points of C and C++.  But, it’s clear that now other problems have come to the fore: dependency management, version control, testing and so on.  I guess you always have a biggest  problem.

When the current solution is simple, and there is money available, there will be a tendency to complicate the solution to capture missing use-cases, making the solution more complex.  As the solution becomes more complex, change becomes harder.     This is orthogonal to the defect rate of the system.  It’s not necessarily the case that the more complex system will have fewer (or more) defects.  Where defects are measured as deviations from the ideal system.  

<b>Prescriptions</b>

Is it possible to escape this trap? 

<ul>
<li>We can’t go backwards, to <b>a point of lower functionality</b>, even if the lower functionality place has fewer defects.    That’s because, it would then be necessary to somehow <i>prove</i> that we had fewer defects.  And that might mean understanding our existing system.</li>
<li><b>Going forwards</b> gets harder all the time.  More and more time is consumed in <i>testing</i> and in <i>specifying</i> the software.  It’s a waterfall process, and the waterfall is enormous.  </li>
<li>We could start capturing the behaviour of the system as a <b>set of tests.</b>  But the problem is, there is no instant payoff for these, they would necessarily span multiple systems and they would be fragile.  </li>
<li>We could start building <b>maps of the territory,</b> but the problem is that the territory changes and the maps are continually out-of-date. </li>
<li>We could start doing <b>pure functional</b> programming.  Because, then you know your inputs and your outputs.  But really, I wouldn’t know where to begin on this, in any environment with multiple databases, outputs going to different places etc. etc.  </li>
<li>We could try going in an <b>agile</b> direction, that is: try to release early, and often.  And code small changes.  This may simply be impossible, given the risk-aversion and the complexity of the environments.</li>
</ul>

Honestly, right now I don’t know what the solution is.



     





]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>223</wp:post_id>
		<wp:post_date><![CDATA[2015-10-09 11:09:30]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2015-10-09 11:09:30]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[ramp-up-to-the-point-of-impossible]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="post_tag" nicename="blog"><![CDATA[blog]]></category>
		<category domain="category" nicename="management"><![CDATA[management]]></category>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
			<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
	</item>
	<item>
		<title>The Pitfalls Of Regression Testing</title>
		<link>http://robmoff.at/2015/10/09/the-pitfalls-of-regression-testing/</link>
		<pubDate>Fri, 09 Oct 2015 11:09:34 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://robmoff.at/2015/10/09/the-pitfalls-of-regression-testing/</guid>
		<description></description>
		<content:encoded><![CDATA[


<b>What Is It?</b>

Let’s say you have two versions of some software.  A and A*. A* will replace version A at some period in the future.   Because we’ve not bothered to build any automated acceptance tests for either A or A*, we want to make sure we haven’t introduced any faults into A* that A didn’t have.  

Obviously, A might have lots of faults.  But, with regression testing we are able to prove that at least, A* won’t have any new ones.  Or are we?

Regression testing proceeds by running the two systems side-by-side using the same input data, and hopefully producing the same outputs.  Someone will usually write some kind of <i>diff</i> (short for difference) routine to compare the results of the two systems, to see if they are the same.  

Often, this turns into an industry in itself, for reasons we will now go into.  Because, regression testing never works the way you hoped it would.

<b>Number Formats</b>

The first and most trivial problem you run into is that the numbers are different.  For example, one million can, more or less be represented in any one of these ways:

<ul>
<li>1.0E6,</li>
<li>1,000,000</li>
<li>1000000,</li>
<li>1000000.000000000 </li>
<li>1,000,001</li>
</ul>

So, whoever wrote the <i>diff</i> tool, to compare the two systems, now has to consider that the formats are different.  

In the worst case (the last one),  the numbers are <i>actually</i> different. But, not different enough to matter.  Is anyone going to look into why the numbers have changed?  Probably not.  But a dollar here or there is nothing, right?  Right?  What about two dollars? And so on.

<b>Out-Of-Order Processing</b>

The second issue that you run into (and the second-most trivial) is that the results are in a different order coming out of each system.  If A and A* are producing <i>vast</i> quantities of data, this in itself now becomes a software engineering problem, because somehow, you have to <i>sort</i> the two sets of data to be the same, before you can compare them.

Again, this is not the end of the world, but the <i>diff</i> tool gets a bit more complex.  Maybe complex enough to require it’s own database.

<b>Field Changes</b>

Third up, and also quite trivial:  the report formats coming out of A and A* may have changed.  In the best case, A* has added some new columns to the report, and so to compare the results of the two systems, you’re now going to need to understand the column orders and remove the extra ones from the comparison.

In the worst case, A* <i>changes</i> the columns.  If the key changes, it might make it impossible to work out what the row from A was that needs to be compared with A*.  Usually, the mapping is recoverable but, yes of course the diff tool takes on more complexity.

<b>File Formats</b>

Maybe the original, CSV format of A is proving cumbersome, and A* is now using XML or JSON or protobufs or something crazy.  Of course, poor <i>diff</i> now has to convert either the new format back to the old, or the old format to the new, in order to compare them.  

Sometimes, for backwards compatibility, A* will continue to also producing CSV format.  So that’s helpful for the <i>diff</i> tool, right?  Well, some.  But are you sure that the data in the XML format is consistent with that in the CSV?   How do you know?

<b>Methodology Changes</b>

Things are starting to get serious now.  But at this stage, we’ve spent considerable efforts building <i>diff</i> and also it’s brother, <i>diff-xml</i>, so we’re kind of committed.   The next change you start to see is that, obviously, we have made improvements in A to get A*, so actually, there are some differences because A* is deliberately different from A.  

This is great - these are the changes we wanted to see.  This means the software is right, yes? Well, possibly.  Some of the values are different.  But are they different <i>correct</i> or different <i>broken?</i>  If you’re lucky, (and you have a good programmer) you might be able to get around this problem with some clever enhancements to the <i>diff</i> which either exclude any differences due to the change, or compare in some way that takes into account the methodology change. But, probably not.  

<b>Aggregation Changes</b>
<b></b>
This is where it gets <i>really</i> tricky: let’s say the output of A and A* is to aggregate some input. But, the way in which aggregation is performed has changed.  You might end up with different row counts in A and A*, and no way to reconcile them at all.   This is pretty much curtains for the diff tool, unless it only affects a few of the rows and you can exclude again.

<b>Non-Determinism</b>
<b></b>
This problem is that perhaps A and A* may not produce the same results each time they are run.   This means you can’t even regression test A with itself, let alone something new.  ‘A' may also use a back-end service in the production of its results, so even if the code in A itself is deterministic, it may be reliant on something that isn’t.  How will you work around that?

<b>Human Factors</b>

The likelihood is, whenever you run the <i>diff,</i> someone has to eyeball the exceptions it produces.  They’ll probably be ok with this the first time, so long as there aren’t too many to look through.  After a while though, they’ll probably cheerfully tell you things are fine, even when they’re not.  They were fine the other day, so <i>whatevs</i>.  

If none of the other issues warn you against regression testing, this should be the big one:  people are not designed to repetitively do <i>anything. </i>Without oversight, they will cut corners.  Don’t put them in this position: it’s not fair.

<b>Too Much Trouble</b>
<b></b>
One of the biggest problems is that, eventually, it’s probably too much trouble.  You have to get both systems up and running at the same time, with the same input data, and deterministic services, and you might have to access the production systems for this, and then get the data out of them, and then run the diff tool and eyeball the numbers.  You’ll probably have to clone databases so that A* has the same data as A.  You’ll probably have to do that every time you run it as A is a live system...

In the end, the payback of regression testing is probably slight.  But, if you can confidently say that none of these issues is going to present a serious problem to you, then by all means, skip writing acceptance tests and go ahead.



]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>224</wp:post_id>
		<wp:post_date><![CDATA[2015-10-09 11:09:34]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2015-10-09 11:09:34]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[the-pitfalls-of-regression-testing]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="post_tag" nicename="antipatterns"><![CDATA[antipatterns]]></category>
		<category domain="post_tag" nicename="blog"><![CDATA[blog]]></category>
		<category domain="category" nicename="software"><![CDATA[software]]></category>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
			<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
	</item>
	<item>
		<title>Waterfall Is Broken</title>
		<link>http://robmoff.at/2015/10/09/waterfall-is-broken/</link>
		<pubDate>Fri, 09 Oct 2015 11:09:37 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://robmoff.at/2015/10/09/waterfall-is-broken/</guid>
		<description></description>
		<content:encoded><![CDATA[


But people keep on doing it.  Why?

It’s the go-to methodology: build stuff, then test it with humans and then release it.  Problem is, that we get into a situation where it’s not testable, and therefore not releasable.  The reason waterfall is still popular is that it requires the <i>least up-front investment in anything</i>.  Literally all the cost of the project is accrued later on.  

Compare with Agile.  Nobody does this right.   Why is that?  One reason is that the practices are <i>many</i> and <i>hard.  </i>It’s really impossible to nail down exactly what agile is, what it means.  So, everyone just says they do it, but really, they don’t.  It has up-front costs of understanding the methodology, and writing tests and the planning game, and getting the on-site users.  

But, are people even doing waterfall?   Not PMBOK style waterfall, anyway.  Gathering requirements is <i>hard</i>.  Getting people to agree to requirements is hard.  Often these two steps are abbreviated or committed in the waterfall approach.

An observation is that, if a practice has a high up-front cost with a belated pay-off, it will be ignored.  This makes sense on a human level.  We don’t like doing things now that only reward us later on.  This encourages procrastination.

<b>What is the Problem Then?</b>

Each approach is bondage-and-discipline, in a different way.  Done correctly, Agile may be the more successful methodology, but it requires more members of the team to adopt the B&amp;D, and you adopt it by changing how you behave <i>before it pays off.</i>   However, Waterfall catches you later on, at the end, when everything starts to go wrong.

A <i>humane development methodology</i> would not make you do work now for a later pay-off.  It would make you do work now for a pay-off now.  How can we reconfigure waterfall and agile so that this happens?

]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>225</wp:post_id>
		<wp:post_date><![CDATA[2015-10-09 11:09:37]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2015-10-09 11:09:37]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[waterfall-is-broken]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="post_tag" nicename="antipatterns"><![CDATA[antipatterns]]></category>
		<category domain="post_tag" nicename="blog"><![CDATA[blog]]></category>
		<category domain="category" nicename="management"><![CDATA[management]]></category>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
			<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
	</item>
	<item>
		<title>Response to Agile Principles</title>
		<link>http://robmoff.at/2015/10/13/response-to-agile-principles/</link>
		<pubDate>Tue, 13 Oct 2015 22:13:32 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://robmoff.at/2015/10/13/response-to-agile-principles/</guid>
		<description></description>
		<content:encoded><![CDATA[


<b>&quot;Our highest priority is to satisfy the customer through early and continuous delivery of valuable software.&quot;</b>

<ul>
<li>Is this satisfying the customer?</li>
<li>Does the customer always want software continuously delivered?</li>
<li>Do they want it early?</li>
<li>Is there such a thing as too early?</li>
<li>I think the customer would often happily trade off “Early” for “some semblance of finished”.  Early means re-testing.  Early means trying to use something with features you need missing.</li>
</ul>

<b>&quot;Welcome changing requirements, even late in development. Agile processes harness change for the customer’s competitive advantage.&quot;</b>
<b></b>
- Is there actually just one customer?
- We should be working out ways to prevent requirements changing, and also to elucidate requirements early on.  
- Often, the requirements are only really apparent after some software has been written.
- But, often the requirements aren’t there because people haven’t sufficiently thought them through.
- There is no reward for coming up with decent requirements early on.

<b>Deliver working software frequently, from a couple of weeks to a couple of months, with a preference to the shorter timescale.</b>
<b></b>
- The reason for this is <i>not</i> get value delivered early on, per se.  It’s to get feedback loops.
- Also, the reason is that by practicing deployment early, you get good at it.
- But, there are hidden costs to deploying software (even with CI/CD).  People want to check it.  There are often forms to fill in, security reviews to do, and so on.   
- Software with only a few features might not be worth using at all.

<b>Business people and developers must work together daily throughout the project.</b>
<b></b>
- Except this happens never.  If they spent all their time with developers, they wouldn’t be business people.
- This is the single biggest failure of the agile process.  Business people (the people you need to help you) are <i>always</i> too busy to spend much time on the project.

<b>Build projects around motivated individuals. Give them the environment and support they need, and trust them to get the job done.</b>
<b></b>
- Invariably, no project is an island.  Often you have to interact with system B, etc.

<b>The most efficient and effective method of conveying information to and within a development team is face-to-face conversation.</b>
<b></b>
- Developers hate talking to each other.
- People are often working in other countries, in other time zones.
- Face to face conversation is OK, but you need to write things down so that you remember what was said
- Often, everyone disagrees.  You sometimes need sign-offs.
- Lists are really useful.  
- Conversations are lost the moment they are complete.  No one ever remembers conversations the same.  Often, important people are excluded from conversations. 
- I conclude that this is very inefficient and very ineffective. However, it still might be for some use-case the most efficient and effective.  This is a shame.  
- Open source software gets built with almost none of this.  Explain.  
- Groupthink.
- Design By Committee. 
- There are clearly more productive ways to develop ideas. Our brains somehow do it (organising the thoughts of billions of neurons).  This is why art is a one-person-show.  If only we could access these organisational constructs.
- Right now I am in an <i>online meeting.  </i>We have <i>a list of actions.  </i>We are taking <i>notes</i>.  We are assigning <i>blame</i>.  We are capturing <i>issues in a list</i>.  It’s all kind of ad-hoc.  None of this is face-to-face communication.   There is a continuum here of online, offline, ad-hoc, recorded, signed-off, tracked, untracked communication.  Why?

<b>Working software is the primary measure of progress.</b>
<b></b>
- Which is measured how, exactly?
- What constitutes working? 
- How do we weigh the software we have working?
- Maybe this is counterproductive.  Less software is better than more.
- Bill Gates: “SLOC is like measuring completion of building aircraft by weighing it”.

<b>Agile processes promote sustainable development. The sponsors, developers, and users should be able to maintain a constant pace indefinitely.</b>
<b></b>
- This isn’t even a principle.  It’s just two sentences saying what you hope will be true about the world.

<b>Continuous attention to technical excellence and good design enhances agility.</b>

- I think this is another way of saying, get rid of technical debt.  

<b>Simplicity--the art of maximizing the amount of work not done--is essential.</b>


- I think this is another way of saying, get rid of technical debt.  


<b>The best architectures, requirements, and designs emerge from self-organizing teams.</b>
<b></b>
- If this is true, why do we need agile to tell us how to organise things then?

<b>At regular intervals, the team reflects on how to become more effective, then tunes and adjusts its behavior accordingly.</b>
<b></b>
- This is really just the Lean/Deming/ISO9000 thing all over again.  Is this even true anymore?  Why do teams only concern themselves with their own processes?  Can’t teams learn from each other?  Why does each team have to re-invent the wheel.  
- Isn’t software supposed to be some unique thing?  Shouldn’t things change as they go along?  

]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>247</wp:post_id>
		<wp:post_date><![CDATA[2015-10-13 22:13:32]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2015-10-13 22:13:32]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[response-to-agile-principles]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="post_tag" nicename="antipatternsblog"><![CDATA[antipatterns,blog]]></category>
		<category domain="category" nicename="management"><![CDATA[management]]></category>
	</item>
	<item>
		<title>Visibility:  The Greatest Loss</title>
		<link>http://robmoff.at/2015/10/16/visibility-the-greatest-loss/</link>
		<pubDate>Fri, 16 Oct 2015 14:38:32 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://robmoff.at/2015/10/16/visibility-the-greatest-loss/</guid>
		<description></description>
		<content:encoded><![CDATA[


I am starting to believe that the reason programming is difficult is because of the visibility issue:  There is no relationship between the code you type on the screen, and what comes out of the other end.

It requires a strange imagination to bridge the gap from one to the other.  Not to mention an overwhelming desire or need to get something done.

The closest that the man in the street gets to programming, is with Excel.  Even Excel <i>ruins</i> visibility.  It’s really easy to lose track of how a calculation works in Excel: there’s nothing preventing that happening.  How is this cell calculated?  Well, I can see the names of the cells being referenced. If I click, I can see them: the important cells get highlighted in rainbow colours and I can see what connects to what in the formula.   But, I have to interact with Excel to get this to happen:  the model is built in my head, through my exploration of the sheet.  I am not shown the model, I have to construct it myself, cell by cell. 

<b>Visibility is the most easily-destroyed helpful property of software</b>
<b></b>
It’s not even something that’s really mourned after it’s gone.  The visibility remains in the mind of the developer.  Just like, if I hide a ball behind a curtain.  There’s no loss to me:  I <i>know</i> the ball is behind the curtain; I put it there.  The loss is to time, when the ball is forgotten, or to the next person, who needs to know where I put the ball.

But, if we want to create systems that <i>can be understood</i> then visibility is <i>really really important.</i>  

<b>Banking Risk</b>

If you are building a computer game or a website, then this is not a problem that affects you too much:   it’s all on-screen.   Arguably, you can’t just eyeball in either case:  to see some features of the game or website you’ll need to<i> </i>interact with it.  So, there are things that are invisible until you explore.

But, in the world of banking risk, everything is invisible.  Numbers are completely <i>meaningless</i> until you introduce some <i>visualisation.  </i>But, visualisation is expensive.  Yes, you can put some numbers into an Excel spreadsheet.  But it’s still quite a lot of work for IT guys to take numbers and display them meaningfully.

<b>Wilful Loss Of Visibility</b>

Sometimes, people deliberately want to obfuscate the logic and meaning in order to build privileged positions for themselves.  I see this happening at work, but Michael Lewis does a good job of representing this in <i>Flash Boys</i> too:  people profit from obfuscation:  <i>In the land of the blind the one-eyed man is king.</i>

<b>Abstraction</b>
<b></b>
Abstraction is a key feature of most programming languages:  the ability to introduce an <i>indirection</i> to say:  these cases are all examples of a more general case, so use the general case.  But, as soon as we have this indirection, we lose visibility over what is actually being done.  This is <i>the cost of abstraction. </i>
<i></i>
Indirection means that my feet can operate the pedals in the car, but I don’t know what is actually happening after that.  
<i></i>
<b>Encapsulation</b>
<b></b>
The mere idea of encapsulation is an affront to visibility:  you are saying:  “This here is a machine.  You don’t need to know how it works inside.  Use the interface and it will keep you from doing anything with the machine that you’re not supposed to do”.  

But, this is like my washing machine at home.   I have literally <i>no idea</i> of what’s going on inside it.  I put the clothes in.  I press some buttons.  There’s water involved.  Clothes come out clean.  

Visibility is also the <i>cost of encapsulation.  </i>I can interact with the device through its simple interface.  But, as a result of providing me that simple interface, the manufacturers have (possibly deliberately) hidden from me what goes on inside.

<b>Modern Software Techniques Are Failing Us</b>
<b></b>
These tools:  encapsulation, abstraction, are <i>useful.  </i>But, they don’t come without cost.  Can we not have tools which allow us to work without this cost?  

Part of the problem is the <i>map and territory</i> issue.   When we design software, we end up with a bunch of bytes on a computer disk, that make sense to the computer.   They make no sense to us.  People don’t work this way.    When the programmer creates the program, he is primarily concerned with communicating to the computer <i>what it needs to do.  </i>But then, we’ve added layers on top to make it easier for the programmer to use his mental faculties over time.  Things like, assemblers, third generation languages, object orientation. 

<b>The Real World</b>

But this is analogous to the <i>real world:</i> “Stuff” is just atoms.  And atoms don’t make sense to us.  Our senses are all about managing the signals produced by these atoms, and converting them into something upon which information processing can be done.  

From this, we develop <i>mental models</i> of things:  mental maps of territories, mental models of people’s behaviour.  Mental feedback loops: “if I eat this, I will feel full”.  

In the real world, people have to do <i>lots of work</i> to build maps, guides, teachings that other people can use to understand the world in the way they do.  

If we conceptualize a computer program as a foreign land, it’s almost as if the programmer is primarily sculpting this landscape, but not producing any maps for it: people are forced to learn the territory themselves, or treat the whole thing like the washing machine and <i>not worry</i> about how things happen. 

<b>Brain-Computer Interface</b>

Tools (like Eclipse, and Excel, say) don’t just try and reduce our finger-typing.  They are a brain-computer interface.  In order to fully exploit the pattern matching and inference-building techniques in the brain (the uniquely human talents which we don’t yet understand how to build in software), we need to <i>increase the surface area</i> between the human and the computer.

Since we can’t change human perception (yet), this means that software has to <i>adapt to exploit the human perceptive system.  </i>This means, on a basic level:
<ul>
<li>Using colours (e.g. to highlight our code)</li>
<li>Using indentation to give structure (geography). </li>
<li>Using <i>visualisations</i> where possible, instead of tables of numbers.</li>
<li>Using <i>words</i> and <i>iconography</i> over pure opcodes.</li>
<li>Graphs and Maps at different levels of abstraction / scale.</li>
<li><i>Domains:  </i>subdivision of the space so that you only need to consider parts in isolation.</li>
<li>Sound? </li>
<li>Smell!?</li>
</ul>

Obviously there are areas that programming doesn’t exploit well at the moment:  geographic structure is <i>really really poor.  </i>Programs and data are often represented in trees (or, hierarchical structures).  These trees tend to be <i>canonical</i>, in the sense that they are <i>one particular tree</i>, rather than a choice from all possible trees.   For example:   java classes are shown in a package structure in Eclipse.  However, you could show them in an import-dependency structure.  This wouldn’t then be a tree, it might have cycles in it.  

<b>Machine Code &amp; Beyond</b>

What something like assembler language does, is transform machine code into something more <i>visible and human.  </i>Abstract numbers become <i>instructions.  </i>We have removed (or at least, created a simpler) layer of indirection.  This improves visibility:  we are trained to recognise words and their meanings.  So, assembly language is the first example of improving visibility via the BCI techniques described above.

After assembly, we went beyond this:  Java, Lisp or Haskell (or any 3GL) use keywords profusely, and you get to define your own lexicon.  

Further, Java, Lisp and Haskell all take different approaches to reducing the problem space.   Java uses object orientation to reduce the scope of what you have to visualise in one go.    This is again another concession to the human visualisation system: &quot;we know you can’t visualize <i>anything</i>, but you can visualise some smaller domain”.   Lisp uses its single list abstraction.  Haskell uses pure functions.  

Excel uses both <i>pure functions</i> and <i>geography.  </i>
<i></i>
None of them are particularly rich in higher-level abstractions.  Java for example has packages, which are fairly weak: you can create all kinds of inter-dependencies between packages (and the objects within them) which destroy any kind of coherence  / loose coupling that the package has.

<b>Life</b>

If we want to build new, better languages, and improve the way we do things now, we need to take the hints from nature.  Obviously, this table is wrong, but it serves to indicate that we have a lot more to do:


<table>
<tr>
<td>
Life Level
</td>
<td>
Computing Level
</td>
</tr>
<tr>
<td>
DNA / Proteins / RNA / Amino Acids
</td>
<td>
Machine Code / Bits / Bytes
</td>
</tr>
<tr>
<td>
Organelles / Viruses
</td>
<td>
Functions, Methods, Data Structures
</td>
</tr>
<tr>
<td>
Cells
</td>
<td>
Objects / Source Files
</td>
</tr>
<tr>
<td>
Organs
</td>
<td>
Packages ?
</td>
</tr>
<tr>
<td>
Phenotypes
</td>
<td>
Programs
</td>
</tr>
<tr>
<td>
Families
</td>
<td>
Operating Systems / Servers
</td>
</tr>
<tr>
<td>
Societies
</td>
<td>
Organisations
</td>
</tr>
</table>

<b>Questions Arising</b>

<ul>
<li>If these different levels of hierarchy are so useful, why can’t you define <i>more of them?</i></li>
<li>Pure4J shows that you can do a lot with annotations.   Could we also have annotations to describe this kind of super-structure in Java, say?</li>
<li>What benefits would that give us?</li>
<li>We currently deploy and run stuff at the program level.  We are starting to move up to the next level with things like Docker (i.e. OS/Server level).  But this is hopeless when we have a whole Bank to change!  What would it look like if we could manage everything together?</li>
</ul>
<i></i>
<i></i>




]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>249</wp:post_id>
		<wp:post_date><![CDATA[2015-10-16 14:38:32]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2015-10-16 14:38:32]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[visibility-the-greatest-loss]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="category" nicename="software"><![CDATA[software]]></category>
	</item>
	<item>
		<title>Logging Vs Breakdowns (A Reporting Pattern)</title>
		<link>http://robmoff.at/2015/10/16/logging-vs-breakdowns-a-reporting-pattern/</link>
		<pubDate>Fri, 16 Oct 2015 14:38:34 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://robmoff.at/2015/10/16/logging-vs-breakdowns-a-reporting-pattern/</guid>
		<description></description>
		<content:encoded><![CDATA[


Recently at work, we have been discussing our risk flow application, and discussing how logging should work.  The question is:

<i>When a business-user has an issue with the report, how will we log the details and information used to construct the report?</i>
<i></i>
Discussion has centered around a standardized logging format, or a standardized location for where this logging information should go.  However, I think all of this misses the point, and instead, you should introduce a pattern, the Self-Consistent Report Pattern.  I will discuss this in detail further down, but before I do, let’s look at...

<b>What’s Wrong With the Logging Idea</b>

The problem is this:  The business receive report A.  However, they are concerned that report A is wrong.  This means that either:
<ul>
<li>the data coming into report A is wrong, or</li>
<li>the calculation performed in report A is wrong.  </li>
</ul>

Obviously, now they have to investigate further.  So, the next step is to get hold of the aforementioned log files.    Now, maybe this means a call to the IT team.  Or, maybe there is a service that the logs can be pulled back from.  Either way.

Having got hold of the log files, they then need to <i>parse the log files</i> looking for the information related to the error they found.  Maybe there are four or five items of information that come in, and they have to find each of these in the log file.   

Next, they can use this information to try and perform the same calculation that was on the report.  If they come up with the <b>same result</b>, then they know <i>something must be wrong with the input data.</i>
<i></i>
If they come up with a <b>different result,</b> then they know, <i>something is wrong with the calculation.</i>
<i></i>
One final thing that could happen is that they realise that actually, <i>they</i> were wrong, and in fact, there’s no problem.  But, excepting this, they can then go write up a bug report.  

So, what’s wrong with that?  Multiple things:

<ol>
<li>The business user now has two separate sets of data coming in.  The report and the log.  There’s a potential for error here:  what if he gets the wrong log?  What if the log is deleted?  </li>
<li><i>Logs</i> tend to be full of stuff.  The business user doesn’t care about all the stuff to do with SQL queries,  heartbeats, message queues.  They just care about the input data and the calculation.  So this stuff obfuscates what’s needed.</li>
<li>There’s every chance that the developer hasn’t included what’s needed in the log file.  In which case, nothing can be done.  Is there any way that we can ensure the log contains everything needed?  Possibly not.</li>
<li>Once the business user gets <i>just the information he’s interested in</i>, he still has the problem of tying up this information with the information in the report. Maybe that means lots of data merging and pulling stuff into Excel.  Either way, that’s big bit of work to do, and a likely source of error, even before he gets to the calculation.</li>
</ol>

So how can we fix this?

<b>The Self-Consistent Report Pattern</b>
<b></b>
Let’s solve this problem by adding a single constraint to our report format:

<i>“The report should contain both it’s input and output data.  The output data should all be derivable entirely from the input data.&quot;</i>

So, this is to say that if we have a calculator that (trivially, here) sums up values <i>A, B &amp; C</i> into a result R, then A, B, C and R should all be on the sheet, like so:

<table>
<tr>
<td>
<b>A</b>
</td>
<td>
<b>B</b>
</td>
<td>
<b>C</b>
</td>
<td>
<b>R</b>
</td>
</tr>
<tr>
<td>
5
</td>
<td>
9
</td>
<td>
4
</td>
<td>
18
</td>
</tr>
<tr>
<td>
2
</td>
<td>
11
</td>
<td>
2
</td>
<td>
15
</td>
</tr>
<tr>
<td>
1.5
</td>
<td>
8
</td>
<td>
4
</td>
<td>
12.5
</td>
</tr>
</table>

At a stroke, this has solved problem 1 and 2 and 4 we identified above:
<ul>
<li>There is no need to get a separate log, it’s all here (1).</li>
<li>Done right, the report contains <i>only the information you’re interested in</i>, and not every single attribute of data ever loaded (2). </li>
<li>There’s no need to do the matching manually, it’s done for you (4).</li>
</ul>

What about problem 3?  This is something you can <i>verify</i> by loading the report into Excel and figuring out whether it’s self-consistent or not:  you get some business user to try and validate the results, based on the information that’s given to them, and <i>nothing else.</i>

But obviously, if you go this far, you could just <i>automate that test</i> and write an acceptance test that makes sure that the results on the sheet can be calculated, so the business user doesn’t need to do it over and over for each release.

<b>The Self-Consistent Report Pattern: Reloaded</b>

You can go one step beyond this, and actually add your testing code <i>into the report itself.  </i>That is to say, the system responsible for producing the report is also responsible for testing the consistency of the report <i>before it is published.  </i>Essentially, you are building the acceptance test into the report itself.  

This last idea works especially well when the report is at multiple levels, or roll-ups (Maybe a trade level and a counterparty level, or line-items and totals).   You might produce these two distinct levels in different tabs of an Excel sheet, or in different files, but you can run the consistency check across all of the levels, to ensure the counts match up, or the totals match up to the line-items.  



]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>250</wp:post_id>
		<wp:post_date><![CDATA[2015-10-16 14:38:34]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2015-10-16 14:38:34]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[logging-vs-breakdowns-a-reporting-pattern]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="category" nicename="software"><![CDATA[software]]></category>
	</item>
	<item>
		<title>Why Are We Not All Just Building Things In SQL Databases?</title>
		<link>http://robmoff.at/2015/10/21/why-are-we-not-all-just-building-things-in-sql-databases/</link>
		<pubDate>Wed, 21 Oct 2015 21:20:34 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://robmoff.at/2015/10/21/why-are-we-not-all-just-building-things-in-sql-databases/</guid>
		<description></description>
		<content:encoded><![CDATA[


It should have been so easy:  transactional datastores, functional query languages on top of them, and then a programming language to modify stuff.  The promise of the DBMS.  But what went wrong?  Why do we have such a messy, complex landscape?

One problem is the cost:  databases <i>used to be</i> hideously expensive.  A second is the language:  programming in SQL <i>sucked.</i>  And while things like Oracle tried to bolt on Java as best they could, this always seemed… messy.   Coding everything with stored procedures didn’t work. 

And then there was the web:  Databases were a poor option if you wanted to build interactive web pages, whereas servlets gave you the freedom to do <i>anything</i> that the protocol supported.  So, really there was no choice.  In order to build web-enabled applications, people were forced outside the DBMS to deliver them.  

Another thing is separation of concerns:   If you build <i>outside</i> the database, then maybe you can swap the database for something else, at some future time.   This never happened, in reality, but at design-time it gave you extra choices.

What about in banks?  Going back, I remember the GriMis database at DB: you put risk numbers in, and they were pulled back into the report server.  It had to be this way as the databases weren’t fast enough to do the reporting themselves.  So, again, the databases let the side down.  Otherwise, you could have achieved the same result doing just SQL, and we could have saved the man-years of effort building the report server first in C++ and then in Java.

Somehow, over time, databases got relegated to the role of just being data stores, and application servers took over creating transactions for them and hosting the applications.   Somehow, this was <i>faster</i> (despite extra networking costs).  And, this allowed databases to scale horizontally into the unmanageable mess of one-for-each-app rather than just vertically one-for-the-whole-enterprise which was bound by the size of the DBMS architecture and the hardware it ran on.

It’s not hard to see how you go from this fragmented picture to where we are today:  in each case, the short-term advantage of building something now trumps the long term homogeneity of the environment.  And so, we end up in massively heterogeneous environments: there is no long term.  The only place that homogeneity exists <i>is at the network layer.</i>    

Lessons:
<ul>
<li>Heterogeneity wins, because decisions about complexity are made considering only the short-term.  </li>
<li>Heterogeneity wins, because, having given up the long term, people optimise on the problem areas they are facing, rather than considering the big picture.</li>
<li><i>How did homogeneity win at the network layer??</i>  There were standards, they bought the same wires for the whole building, maybe the problem domain was small enough that they could consider it all in one go, also there are ways to convert between one network and another.</li>
<li><i>Do One Thing Well.  </i>You can’t possibly solve all problems in the database.  You need to go wider.  So, programming languages were always going to be a separate thing to the database layer.  They couldn’t own the whole picture.</li>
</ul>



]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>251</wp:post_id>
		<wp:post_date><![CDATA[2015-10-21 21:20:34]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2015-10-21 21:20:34]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[why-are-we-not-all-just-building-things-in-sql-databases]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
	</item>
	<item>
		<title>Round-Trip Transformations</title>
		<link>http://robmoff.at/2015/10/30/round-trip-transformations/</link>
		<pubDate>Fri, 30 Oct 2015 07:29:36 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://robmoff.at/2015/10/30/round-trip-transformations/</guid>
		<description></description>
		<content:encoded><![CDATA[


Following on from “Logging vs Breakdowns”, here is my second Banking pattern:

<i>Apart from pure calculations, all other data manipulation should be round-trip transformations.</i>

<b>Examples</b>
<b></b>
<ul>
<li>CRUD operations:  <i>Store some data in the database, read it back. (Upsert/read or Delete/read)</i></li>
<li>Marshalling:  turn data into XML, and back again</li>
<li>Buses:  put a message on a bus, read it off.</li>
</ul>

<b>Read-Only REST Service?</b>

Let’s say you have a  third-party service publishing data.  To get it, you need to make a REST call.  Let’s say, it’s price information on some bonds.  

What are the chances that you have read the price information properly?    Well, Murphy’s law says that if you don’t code this as a reversible transformation, you’ll get it wrong.  So, how can you do that?

Simply, you need to <i>extend</i> the service, so that it is reversible: maybe you create a mock of the (read-only) service, so that you can put data in, and then read it back, and the reading part is functionally equivalent.  (i.e. using the same HTTP protocol etc.) In this case, you <i>are</i> testing all the code, but you are not going to use the writing chunk in reality.

<b>Integrity</b>

A round-trip transformation is a homoiconic representation of the data.  It’s the <i>same data</i> in a different form.   As opposed to a calculation, where fundamentally we are creating something new out of the data.   It should be easy to tell where this pattern applies by asking the question:

<i>Is this operation reversible at all?  Do I have everything I need to revert back to what I had at the start?</i>
<i></i>
I.e.  given f(x) -&gt; y, can f’(y) -&gt; x exist?

If so, you are looking at a round-trip operation.

<b>Write-Only Services?</b>
<b></b>
In a way, it’s even more important to subsume a write-only service into a round-tripable operation.  This is because, <i>you have no idea if what you wrote made it there at all.  </i>Again, it’s essential to mock-and-extend the interface to ensure you are testing the round-trip.

<b>Still Not Perfect</b>
<b></b>
This pattern falls short of perfection: let’s say you have to persist fields A, B and C in the database.  But, on write you transpose A and B, and on read you make the same mistake.  On the database side, your data is wrong.  At your side, it’s always correct.  

Unfortunately, <i>there’s nothing you can do about this.</i> There is always the chance of this happening.  Essentially, you have written the code and the test, and the same error is present in both.   The best you can do is to try and write the read and the write separately, so that you are coding both in a different way.  Otherwise, still it’s <i>tough.</i>
<i></i>
I don’t believe there is a way to solve this problem.   

<b>Notable Exceptions</b>
<b></b>
The obvious one <i>should</i> be logging, but we already tackled this in “Logging vs Breakdowns”.  But, really you should still be logging that you are performing some manipulation.
<i></i>
<b>Suggestions</b>

Break down all the functionality in your process to either round-trip transformations or Self-Consistent reports.  It should be clear from this that data is always bulk-gaining as you go along.  

]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>253</wp:post_id>
		<wp:post_date><![CDATA[2015-10-30 07:29:36]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2015-10-30 07:29:36]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[round-trip-transformations]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="post_tag" nicename="banking-patterns"><![CDATA[banking-patterns]]></category>
		<category domain="category" nicename="software"><![CDATA[software]]></category>
	</item>
	<item>
		<title>Buffet On Short-Squeezes</title>
		<link>http://robmoff.at/2015/11/10/buffet-on-short-squeezes/</link>
		<pubDate>Tue, 10 Nov 2015 08:44:43 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://robmoff.at/2015/11/10/buffet-on-short-squeezes/</guid>
		<description></description>
		<content:encoded><![CDATA[


Reading Buffett today.  He said something amazing.  Talking about the rise of the auto industry in the US, he said (paraphrasing):

“It’s not always possible to predict the winners. However, it’s often easier to predict the losers.  I’m disappointed the Buffett family didn’t hold a short position in horses.  We could have easily borrowed some if there was a short squeeze”

<b>Shorting</b>

In a short position, you are basically selling horses.  e.g. Owning -100 horses.    When the price goes down, you make money.  Then, you can buy more negative horses.  Let’s say a horse costs £100 today.  I sell 100, netting £100,000, but owing 100 horses.  In 3 months, the price declines to £90.  I buy 100 horses, learning the balance.  It costs me £90,000, leaving me £10,000 up.

So, to do this, I would have to <i>borrow</i> 100 horses in order to sell them.  (this assumes I can give back different horses… it would be different if these were <i>specific</i> horses).

<b>Short Squeeze</b>

So, what is a short squeeze?   This is where lots of people hold a short position, and the price of the horses increases.  Maybe it’s harvest time, or something.  In this case, the price might go up.  People with short positions might see their losses increasing and realise that they will go broke if they’re not careful.  

Brokerages have margin accounts.  This is money that you deposit with the brokerage to cover the losses of short-selling, if any accrue.  So, if you held a large short position, you might get a margin call on the account and have to give the brokerage more money. 

Let’s say the margin account balance was £5000.   If the price of horses increased to £105, your short position would be liquidated.  You would end up losing your margin of £5000, because you would spend the whole £105,000 buying back the 100 horses you owed.  (Ignoring <i>options</i> here, for simplicity).  

Otherwise, your short position would be closed before it was the brokerage rather than you that was accruing losses.

<b>Borrowing More Horses</b>

So, if the price increased, Buffet could borrow <i>more</i> horses.  And then, sell those horses too.  And pay more money into his margin account.  This would increase the size of his short position.  But, crucially, he would still be able to cover his margin calls.

He would then be paying borrowing costs on the horses (maybe £5 per horse-month?), rather than covering margin calls.  Arguably, this would be better - he would be able to “ride out” the squeeze.  But, if his long-term bet against the horse failed to pay off, he would be ruined.  

Possibly why his family <i>didn’t</i> do this.


Keynes:

     “The market can stay irrational for longer than you can stay solvent&quot;

]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>254</wp:post_id>
		<wp:post_date><![CDATA[2015-11-10 08:44:43]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2015-11-10 08:44:43]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[buffet-on-short-squeezes]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="post_tag" nicename="banking-patterns"><![CDATA[banking-patterns]]></category>
		<category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
	</item>
	<item>
		<title>Constraints Make For Flexibility</title>
		<link>http://robmoff.at/2015/11/21/constraints-make-for-flexibility/</link>
		<pubDate>Sat, 21 Nov 2015 01:11:10 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://robmoff.at/2015/11/21/constraints-make-for-flexibility/</guid>
		<description></description>
		<content:encoded><![CDATA[


Antione de Saint-Exupery said:

<i>Perfection is reached not when there is nothing more to add, but when there is nothing more to take away.</i>

Which I think, is one of my favourite quotes of all time.  It <i>resonates</i> on a deep level.  And, it’s extremely relevant to computer science, where we talk about YAGNI (You Aren’t Going To Need It) and Refactoring Mercilessly.  It’s also appropriate to the startup community, who talk about building their <i>Minimum Viable Products</i>.   That’s all true. 

Of course you shouldn’t build stuff you don’t need.  It’s waste.  And, waste lying round everywhere just makes everyone’s life harder.  Get rid of it.

But, those things don’t even capture it.  This is also about curation.

Sometimes, by limiting functionality, we end up with <i>more.  </i>Not just, the same, but actually more.

For example.  Pure4J disallows you from doing certain things with code. And, it enforces those rules pretty rigorously.  By <i>limiting what you can do</i>, suddenly, a whole new load of things open up.   Problems that you had before just disappear. 

Here’s another example that I’ve spoken about before:  Creating free-text fields in Jira.  By putting these in, you actually <i>reduce</i> the functionality of the software, because now there are plenty of ways in which information may or may not be stored in the system, and no one can rely on it being there.  By having a fixed, mandatory choice of four options (creating a <i>constraint)</i> you give people something they can use to <i>categorize</i> and search against.  But, with an optional free-text field, it seems like you’ve given them more, but actually, you’ve given them less.  It’s next to useless for any kind of searching or categorizing and may as well not be there.

A third option:  Rich-Hickey’s Datomic database.  It’s basically a layer over <i>a regular database.  </i>And, it prevents you from changing stuff.  So, you can only add things to the database.  <i>How the hell is that better?</i>
<i></i>
It sounds like it should be a disaster.

But, it isn’t.

By doing this, you can pass around <i>copies</i> of the database.  You can test in production.   You avoid a whole host of locking and atomicity problems that you had before.  And what have you really lost?   Actually, nothing you couldn’t do without.

So:  disallowing certain behaviours makes a system <i>more flexible.  </i>Don’t give users more than one way to do anything.  Just give them the one, <i>right</i> way.  

Can anyone think of other examples of this pattern in action?



]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>257</wp:post_id>
		<wp:post_date><![CDATA[2015-11-21 01:11:10]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2015-11-21 01:11:10]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[constraints-make-for-flexibility]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
	</item>
	<item>
		<title>My Top 10 Silver Bullets</title>
		<link>http://robmoff.at/2015/11/26/my-top-10-silver-bullets/</link>
		<pubDate>Thu, 26 Nov 2015 13:35:24 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://robmoff.at/2015/11/26/my-top-10-silver-bullets/</guid>
		<description></description>
		<content:encoded><![CDATA[


In the original “Mythical Man-Month”, 1975, Fred Brooks (who said many very insightful things also) posited:
<i></i>
<i>“There is no single development, in either technology or management technique, which by itself promises even one order-of-magnitude improvement within a decade in productivity, in reliability, in simplicity&quot;</i>

Many years ago, I bought the 20th Anniversary Edition of “The Mythical Man-Month” and read the essay  '“No Silver Bullet” Refired’.  (So that would have been 1995).  In this, Fred talks about the potential Silver Bullet of re-use, and is cautiously optimistic. 

I think if he’d written this in 2005 (at which point Java was big news, and we downloaded libraries like Xerces and Tomcat from the internet) he would have said that this had been a resounding Silver Bullet success:  there just needed to be some other things in place first:  like the internet, open source communities, widespread adoption of Java etc.

So, why do people constantly go on about the idea that there are “no silver bullets”?  (Note that I’ve just recently watched <a href="https://videlalvaro.github.io/2015/02/programming-myths.html">this</a>) There totally <i>are</i> silver bullets…  what Brooks wrote in 1975 is not necessarily true today.  

The rate at which technology was improving in 1975 was slower than today.  Given that Brooks’ time-frame was ten years, and there was but one silver bullet, you would expect us to be having more of them today:  ten years is <i>a long time</i> in IT now.  

But, there’s a second problem.  That is, they creep up on you, and become part of the scenery without you even noticing their contribution.   And, it’s really easy to underplay the importance of some massive ground-shift in opinion after it’s happened.  

In a way, this is like AI: as soon as a computer can do it, it’s not AI anymore.  Poor AI.  Self-driving cars, speech-to-text, text-to-speech, etc.  

Here are some silver bullets.   I’m sure there are better ones, feel free to suggest some.

<b>1.  Assembly Language</b>

It’s difficult to underplay the importance of having mnemonics (which imply a meaning) instead of just numbers.  Numbers you have to remember, and hold in your head.  Mnemonics leap off the page and give you a meaning.  It’s a pretty simple translation, granted, but it’s a huge, <i>easy</i> win.  This gives us a clue as to where to find silver bullets in the future:  look for ways in which we can make the task of defining software <i>more human.</i>

<b>2.  Higher Level Languages</b>

Suddenly, <i>anyone</i> can program, by typing stuff in and watching what happens on the screen.  No one has to worry about memory location, bytes, bits, that kind of thing.  Ok, it’s not suitable for everything but still, a huge win.  My favourite example is Excel.  <i>No one even realises that doing Excel formulas is even programming.  </i>You don’t worry about garbage collection, or deployment, or linkers.  But, it’s undeniably happening. 

<b>3.  Library Code</b>

By creating a language that allows <i>libraries</i> to work together, suddenly, the lone programmer doesn’t have to do it all herself.  (This was Brooks’ re-use option).  Also, we have google now.  And github.  I can type a few keywords in and instantly discover all the libraries in a given area.  I have to make a value-judgement on whether any of them are good, but still, I have the choice of <i>not building it myself.</i>

<b>4.  Garbage Collection</b>

So, you don’t have to worry about memory anymore.  Awesome.  A whole set of bugs rendered irrelevant.

<b>5.  Type Systems</b>

Stopping you breaking your memory models.  Catching <i>loads</i> of bugs.  These were probably around when Brooks wrote his book, but maybe wouldn’t have been widely used like they are today.

<b>6.  The Internet</b>

Instead of distributing libraries on floppy disks and charging a lot, you can now download them off the internet.   Also, you can easily find out about libraries and languages that are out there by searching for them, or reading newsgroups or whatever.  Gone are the days when I had to <i>own a manual</i> in order to understand something: I can just download it now.  

<b>7.  Open Source</b>

Not only can you find out how the libraries work, but if you find some like-minded people you can <i>work together</i> on solving a common problem.  A problem shared is a problem halved.  Or whatever.   It’s self-organisation on a huge scale.  

<b>8.  Stack Overflow / QA Sites Generally</b>

If downloading the manual doesn’t cover it, just ask a question and then <i>for no money</i> people round the world will figure out the answer for you.  I have no idea why, but it works.

<b>9.  Commodity Hardware &amp; Operating Systems</b>

Brooks talked a lot in the 20th edition about the explosion in micro-computers.   He also talks about consolidation of operating systems, which has made a huge difference.   He would be amazed at what this has become.  Both those things are <i>hugely</i> more advanced now.  We have computers <i>in our pockets.  </i>OS X, Windows, iOS… they’re even <i>free.</i>

I was just going to put <i>Linux</i> here, and say how, we used to have to worry about getting files off one machine and into a format for another machine, and finding the right media to do it... that’s gone away.  Linux standardises at such a high level that you can <i>assume</i> so much about the platform you’re running on.

Also, we now even have cloud computing - you can just <i>provision hardware</i> in seconds.  It used to take <i>months</i> to buy kit and get it set up and connected to the internet.  

<b>10.  Web Standards</b>

To put my software in front of users, I don’t have to send them a CD with a <i>client program</i> on it anymore.  No, I just point them to a “URL”, whereupon their browser will download the client in “HTML”, “Javascript” and “CSS”, and, even though they might not be using exactly the same browser as me, it’ll run for them anyway, and they’ll see my software.

Even just the <i>improvements</i> to browsers over the last ten years have been huge.   Anyone remember programming for IE4 or 5?  

<b>Epilogue</b>

Brooks signs off the book in an epilogue called “Fifty Years of Wonder, Excitement, and Joy”.  And he’s totally right.  The silver bullets are coming thick and fast.  I expect to see golden bullets in my lifetime.  As he says:

<i>“Not only is the end not in sight, the pace is not slackening.  We have many future joys&quot;</i>

]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>258</wp:post_id>
		<wp:post_date><![CDATA[2015-11-26 13:35:24]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2015-11-26 13:35:24]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[my-top-10-silver-bullets]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
	</item>
	<item>
		<title>Homo Connectus</title>
		<link>http://robmoff.at/2015/11/29/homo-connectus/</link>
		<pubDate>Sun, 29 Nov 2015 20:32:00 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://robmoff.at/2015/11/29/homo-connectus/</guid>
		<description></description>
		<content:encoded><![CDATA[


Just as <i>Homo Sapiens</i> (humans in tribes, hunting and gathering) evolved into <a href="https://en.wikipedia.org/wiki/Homo_economicus"><i>Homo Economicus</i></a> (humans as  a whole ecosystem, using money to decide who exploits which niche), we have evolved again.

We are now <i>Homo Connectus:  </i>Humans as one hive-mind organisation, with the knowledge of the entire civilisation available to each of us.  

Yes, I’m talking about the smartphone in your pocket.  Twitter.  Facebook.  Blogs.   24-Hour Rolling News.  It’s truly exhilarating to have watched this change unfold during my lifetime.    

For the first time, the whole planet is waking up as a collective consciousness. 

Or perhaps it shouldn’t be waking up - more like, being born.   We’re in the early years of learning to talk to one another, discovering the thoughts of everyone else, getting to grips with different viewpoints and opinions on an unprecedented scale.

We are only just beginning to learn to <i>organise discourse</i>.   Reddit, for example, is a site which allows anyone to create a category.  Then, within that category, discussions happen.   (Hacker News does the same thing for a single category).

We have issues with trolls, and confidence tricksters and fishing, and bullying and baiting.

Different viewpoints on things like racism, sexism, humour, politics cause <i>vast amounts of discussion.</i>  Not much of this is useful.  We need ways in which we can organise discussions better than a temporally-threaded web-page.   We need artificial intelligence to help us do this.   Actually, before that, we need systems that help us do this.

It’s really early days.  We’re at the level of infant-school playground right now.  But, we need new tools and techniques to help us get through the <a href="https://en.wikipedia.org/wiki/Eternal_September">Eternal September</a>.



]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>259</wp:post_id>
		<wp:post_date><![CDATA[2015-11-29 20:32:00]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2015-11-29 20:32:00]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[homo-connectus]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
	</item>
	<item>
		<title>All About Eve</title>
		<link>http://robmoff.at/2016/01/13/all-about-eve/</link>
		<pubDate>Wed, 13 Jan 2016 11:00:39 +0000</pubDate>
		<dc:creator><![CDATA[bobm]]></dc:creator>
		<guid isPermaLink="false">http://robmoff.at/2016/01/13/all-about-eve/</guid>
		<description></description>
		<content:encoded><![CDATA[<b>Some Background:</b>
<b></b>
<a href="https://github.com/witheve/Eve">Eve</a> is a new programming language.  Maybe.  Or, a development environment.  More accurately, perhaps, it’s a tool to think.  If you have an hour to spare, this is a great video to watch from Chris Granger:

https://www.youtube.com/watch?v=VZQoAKJPbh8

If you don’t then I’ll summarise (badly).  The video starts with the question <i>“What will programming look like in 10 years?”.  </i>Chris started off his career with Microsoft working on Visual Studio, but then, faced with the complexity of this product, wanted to build an IDE which stripped back a lot of the complexity, and <a href="http://lighttable.com">Light Table</a> was born (for editing Clojure / Clojurescript).  Light Table aims to minimise or eliminate the cycle between <i>writing code</i> and <i>seeing results</i>.

The lesson from this was apparently, that just fixing the IDE wasn’t enough.  Programming itself suffers from the problem that it is <i>indirect and invisible</i>, beleaguered with <i>accidental complexity</i> and <i>unobservable.  </i>
<i></i>
Paraphrasing heavily (really, watch the video), Eve started as a collection of experiments into how computing could be made better.    They extensively reviewed the existing literature and state-of-the-art, deciding that the closest we have come to really solving those issues of programming are in tools like <i>Excel</i> and <i>SQL</i> (i.e. relational databases).

Along the way, they throw out GUI editors, query visualisations and more traditional text based languages.  Chris then demonstrates version 0 of Eve, which is kind of a Wiki, combined with a query language, and kind of a database.  Everything updates instantly on screen.  There’s huge promise, and I am tempted to <i>get involved in a big, open-source way</i>.

<b>Lotus Notes</b>
<b></b>
My first thought on watching the demo was <i>This seems a lot like Lotus Notes.</i>  And indeed, Wikis and Notes share a lot of common thinking:  unstructured data, functions for manipulating values, views on data etc.

I can imagine that not many people working in IT today are familiar with Notes, but take it from me: this is <i>a complement.  </i>  Notes was an amazing (and amazingly productive) environment to work in.   You could realistically build multi-user applications with workflow, email, reporting, <i>everything.  </i>The security was top-notch.  Lotus Notes came with an Email application, which was built in Lotus Notes, and during the 90’s millions of people used Lotus Notes for Email:  the point being, you could build amazing things in it.

So resurrecting a lot of the ideas of Lotus Notes now <i>makes a lot of sense to me.</i>  We don’t have anything similar to this now, and that’s a shame.  There’s a middle ground (somewhere between building simulations in Excel, and building full applications in Java) which is served badly since we don’t have Notes anymore.

So, good on them.  This seems like a really cool product with a bright future.

But.

<b>I Don’t Think This Is What Programming Will Look Like In 10 Years</b>

If Lotus Notes was so cool, why aren’t we using it today?  Also, if programming in Excel is so awesome, why am I not developing banking software using it?

The problem is, (I think) <i>tradeoffs.  </i>And there are three I want to talk about:
<i></i>
<b>1.  Openness and Accidental Complexity</b>

When you have a closed system (like Eve, or Wordpress, or Lotus Notes, or MySQL, or Excel) you can really put a lid on Accidental Complexity.  Accidental Complexity is things like:  in system A, I have a column called “Name”, but in system B, I have “First Name” and “Last Name”.  Or, here I have dates formatted in the American way, but the file I am importing has them in the European way.  Or, I have an event-driven system which triggers every time there is a new order, but my finance system requires a daily feed… those kind of things.

When you program in a <i>general purpose language</i> like Java, or C++ or whatever, you can deal with accidental complexity, because these languages are like <i>glue</i>: they can join together disparate libraries, or databases, or applications, or feeds, or queues or whatever.  They are “Open”:  they accept that the world at large doesn’t play to any particular rules, and that they need to adapt to the world.

“Closed” systems, on the other hand, <i>force the world to play to their rules.</i>  So, when I write a plugin for Eclipse, Excel, Minecraft, Wordpress or whatever, I have to obey the rules.  That’s fine.  But, a lot of systems that we use every day are out there, not playing to the rules.  Certainly, there are <i>no</i> pre-existing systems playing to Eve’s rules, because Eve’s only just been thought of.

But, can this problem be solved by building “plugins” for Eve?  So that we can get it to talk to existing relational databases, or filesystems, or whatever.  Well yes and no.   Lotus Notes had this challenge already, back in the day.  People wanted it to talk with SQL databases.  Work was done so that data could be synchronised, and maybe that solved a lot of people’s problems.  But inevitably, with this, you <i>imported the accidental complexity from those systems:</i>  table structures, date formats, edit cycles, transactions etc.<i> </i>
<i></i>
So, it feels to me that this is a fundamental issue:  <i>can we build open systems without importing accidental complexity?  </i>Because, if we can’t, then a lot of programming in the future can’t be done in an “Eve” way.

But, maybe that’s ok.

<b>2.  Organisation vs Approachability</b>

In Chris’ video, he talks about how in an early version of Eve, users were bedevilled by <i>scope.</i>  They wanted to use data in functions, but were constrained by not having the data in scope.  He observed that neither Excel or relational databases had this issue, and so, the Wiki-style Eve takes a leaf out of that book and jettisons the concept of scope.

But, scope is a useful thing that was deliberately added to programming languages to reduce errors.  Global state is rightly vilified as being a source of errors in software:  as soon as you scale your software endeavour, you run the risk of confusing pieces of global state.

If you look at many of the features of Java (say):
<ul>
	<li>Separation Of Concerns</li>
	<li>Packages / Namespace / Scoping / Jars</li>
	<li>Interfaces</li>
	<li>Abstract Classes / Type Hierarchy</li>
	<li>Versioning</li>
	<li>Methods / Procedures / Functional Decomposition</li>
	<li>Compilation / Compile-time checking</li>
</ul>
These are all features to improve the <i>organisation</i> of the software, reduce <i>duplication</i> and enforce consistency through <i>once-and-only-once.  </i> Yes, you can build a much more <i>approachable, easy to learn, less indirect </i>language with none of these, but as the scope of your software problem gets larger, the bigger issue is organisation, not approachability.  So, we trade this off.

This is one of the big failings of Lotus Notes:  versioning the software was hard.  Upgrading databases was hard.  <i>Knowing what code was even in the application</i> was hard.  Testing was all manual.  Re-use was minimal.  Revision control (a la git) was impossible.   When you changed something in one place, you had no idea whether this had introduced a problem somewhere else.

And now, it’s actually worse than this.  Right now, I feel that <i>Java (et al) fail us:  </i>It’s still really hard to do releases, and test that software is correct, and ensure that changing a part of the system I’m building is going to have no consequences on other parts of the system.

My client has a vast network of interrelated computer systems, on different release cycles, on different hardware, with different programming languages.. how do we know this all works together?

Yes, pure functional programming would help.  Yes, better testing would help.  Maybe Docker, or Chef could help.

But, right now it’s a mess, and in 10 years time it will be an even bigger mess.   Java allows us to organise at the scale of <i>one application.  </i>But we need tools to help us organise our software at a scale of <i>many applications.  </i>Because, software is eating the world, right?

<b>3.  Focus vs Coverage</b>
<i></i>
Lotus Notes came along when the Internet was in it’s formative years.  So, when you started as a Notes developer, you got given a printed manual or two.  This was great:  everything you needed to know was <i>in the manual.  </i>And, you could be massively productive and run rings around the guys building C++ applications with RDBMS back-ends.  Cool.

What eventually went wrong (I think) was that, as web pages took off, people wanted their Notes databases on the web, and Lotus/IBM then bolted on loads of stuff to make Notes databases web-browseable.  But, it was hard to use and fiddly, and required learning HTML, and the whole conceptual integrity of the Lotus Notes model was lost (see issue 1 again).

The problem is:  one size doesn’t fit everyone.  Also, you can’t hope to keep up with everything.  Software systems <i>at best</i> can hope to serve one niche of people.

It’s the same reason why we don’t <i>just</i> build applications solely in SQL Databases:  at some point in time, companies like Oracle tried to build products where you could build the <i>entire application</i> inside the database, and it would have forms, and web pages and everything.  But, this didn’t work out either:  even ignoring vendor lock-in, it’s better to be able to mix-and-match your technology choices to fit to the problem you have:  trying to be <i>all things to all people</i> is just a non-starter.

This is why Lotus Notes couldn’t keep up: it was too busy trying to do everything, rather than <i>one thing well.</i>

<b>Unfair</b>

And, maybe this is unfair.  What Chris and the Eve team have done is looking amazing.  I don’t think Chris really meant for Eve to be “what programming looked like in 10 years”.  Really, what he was saying  is “we need to start doing more experiments about what programming is, and what it should be, like we did for Eve.”

Eve takes a stance on the three trade-offs above, and it’s pretty much the same stance Notes took:  I loved Notes, and I’d like to see a modern version.   Preferably one which solves things like versioning and so on.

But, the design of “programming in 10 years” needs to acknowledge these trade-offs, and then design <i>beyond</i> them:  truly innovative design should reframe trade-offs in ways which completely change the landscape.  We’re only going to move beyond the current status quo with some amazing design, more experiments, more ideas and throwing away what doesn’t work.

<b>Chris’ Comments</b>
<b></b>
Chris Granger took the time to discuss some of these points with me, on Github:

<a href="https://gist.github.com/ibdknox/2b185fcb8e5d1de68796">https://gist.github.com/ibdknox/2b185fcb8e5d1de68796</a>

<strong>Update #2</strong>

This was discussed further on Hacker News <a href="https://news.ycombinator.com/item?id=10995235">here</a>.]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>261</wp:post_id>
		<wp:post_date><![CDATA[2016-01-13 11:00:39]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2016-01-13 11:00:39]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[all-about-eve]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_oembed_16699f3e52f52beede5fa048326ab1f5]]></wp:meta_key>
			<wp:meta_value><![CDATA[<iframe width="768" height="432" src="https://www.youtube.com/embed/VZQoAKJPbh8?feature=oembed" frameborder="0" allowfullscreen></iframe>]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_oembed_time_16699f3e52f52beede5fa048326ab1f5]]></wp:meta_key>
			<wp:meta_value><![CDATA[1454159602]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
			<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
		<wp:comment>
			<wp:comment_id>42</wp:comment_id>
			<wp:comment_author><![CDATA[Mark]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[mark.r.hacker@googlemail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[146.199.80.199]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2016-01-16 20:40:54]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2016-01-16 20:40:54]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[I think the CardWiki of Eve looks great - as a non-programmer - I could use that now.
I'm a aerospace engineer I work with data a way to query and format that data would be wonderful.
I think the direction is right .]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
				<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
				<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1452976854.839694976806640625;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
				<wp:meta_value><![CDATA[a:3:{s:4:"time";d:1453034420.2514441013336181640625;s:5:"event";s:15:"status-approved";s:4:"user";s:4:"bobm";}]]></wp:meta_value>
			</wp:commentmeta>
		</wp:comment>
		<wp:comment>
			<wp:comment_id>43</wp:comment_id>
			<wp:comment_author><![CDATA[3 – Eve: My Concerns, Discussed with Chris Granger]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://blog.explodingads.com/3-eve-my-concerns-discussed-with-chris-granger/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[54.158.116.132]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2016-01-29 14:22:45]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2016-01-29 14:22:45]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[&#8230;] From: http://robmoff.at/2016/01/13/all-about-eve/ [&#8230;]]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
				<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
				<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1454077365.5792400836944580078125;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
				<wp:meta_value><![CDATA[a:3:{s:4:"time";d:1454077566.424706935882568359375;s:5:"event";s:15:"status-approved";s:4:"user";s:4:"bobm";}]]></wp:meta_value>
			</wp:commentmeta>
		</wp:comment>
		<wp:comment>
			<wp:comment_id>47</wp:comment_id>
			<wp:comment_author><![CDATA[Dave]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[davelnewton@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[38.79.0.242]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2016-01-29 15:00:40]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2016-01-29 15:00:40]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Notes was ahead of its time, like Wave.

Back then we didn't have the tools or mindset that we have today; a modern Notes would be pretty cool.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
				<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
				<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1454079640.7687408924102783203125;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
				<wp:meta_value><![CDATA[a:3:{s:4:"time";d:1454086088.7908079624176025390625;s:5:"event";s:15:"status-approved";s:4:"user";s:4:"bobm";}]]></wp:meta_value>
			</wp:commentmeta>
		</wp:comment>
		<wp:comment>
			<wp:comment_id>85</wp:comment_id>
			<wp:comment_author><![CDATA[Kevin Greer]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[kgrgreer@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://foamdev.com</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[207.198.105.24]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2016-05-05 22:02:48]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2016-05-05 22:02:48]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Nice write-up. Have a look at FOAM (http://foamdev.com and/or https://www.youtube.com/watch?v=S4LbUv5FsGQ) which is a similar but different view of programming in the future.  FOAM is extremely open, given that it uses modeling to support multiple target languages and databases.  It avoids the scope issue by having underlying contexts instead of globals, but hiding them behind declarative imports and exports.

More videos: https://www.youtube.com/channel/UCUmJgdncsCyHO3YAfsk2Kjg]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
				<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
				<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1462485768.8672749996185302734375;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
		</wp:comment>
		<wp:comment>
			<wp:comment_id>54</wp:comment_id>
			<wp:comment_author><![CDATA[Mark W]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[mwdll@icloud.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[208.54.80.221]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2016-01-29 19:46:58]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2016-01-29 19:46:58]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[I think Salesforce.com is the Lotus Notes of today and it is highly successful.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
				<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
				<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1454096818.9603729248046875;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
				<wp:meta_value><![CDATA[a:3:{s:4:"time";d:1454149396.4642579555511474609375;s:5:"event";s:15:"status-approved";s:4:"user";s:4:"bobm";}]]></wp:meta_value>
			</wp:commentmeta>
		</wp:comment>
		<wp:comment>
			<wp:comment_id>57</wp:comment_id>
			<wp:comment_author><![CDATA[All About Eve | robmoff.at | Raony Guimarães]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://raonyguimaraes.com/all-about-eve-robmoff-at/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[159.203.30.30]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2016-01-29 20:15:19]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2016-01-29 20:15:19]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[&#8230;] Source: All About Eve | robmoff.at [&#8230;]]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
				<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
				<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1454098519.663733959197998046875;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
				<wp:meta_value><![CDATA[a:3:{s:4:"time";d:1454149394.8311750888824462890625;s:5:"event";s:15:"status-approved";s:4:"user";s:4:"bobm";}]]></wp:meta_value>
			</wp:commentmeta>
		</wp:comment>
		<wp:comment>
			<wp:comment_id>60</wp:comment_id>
			<wp:comment_author><![CDATA[Kyle Patrick]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[kyle_patrick@yahoo.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[204.50.113.43]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2016-01-29 23:44:41]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2016-01-29 23:44:41]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[As of four years ago when I left, IBM still used Notes internally. As a former Notes developer, and a current Rails developer, I'd go Rails (but I like static typing).]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
				<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
				<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1454111081.7455470561981201171875;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
				<wp:meta_value><![CDATA[a:3:{s:4:"time";d:1454149373.121594905853271484375;s:5:"event";s:15:"status-approved";s:4:"user";s:4:"bobm";}]]></wp:meta_value>
			</wp:commentmeta>
		</wp:comment>
	</item>
</channel>
</rss>
